# 面经总结

## 图形基础

### 1. 图形渲染管线

应用阶段：准备好场景数据（物体、光源、相机）、做一个粗粒度剔除工作，把不可见的物体剔除，不交给几何阶段处理（视锥剔除、遮挡剔除）、设置好每个模型的渲染状态（着色器、合批、渲染目标、渲染路径）、DrawCall

几何阶段：Model, View, Projection 变换， 顶点着色、Projection后，裁剪测试，屏幕映射

光栅化阶段：图元组装、三角形遍历（检查每个像素是否被一个三角网格所覆盖）、三角形覆盖

像素处理阶段：像素着色、透明度测试、模板测试、深度测试、混合

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1677806640736-16415024-2330-41d0-acac-f10feded5e1a.png)

![img](https://cdn.nlark.com/yuque/0/2023/webp/29680306/1689084088378-caf05432-bc6a-4434-9c1f-2302a50e6f1b.webp?x-oss-process=image%2Fresize%2Cw_647%2Climit_0)

### 2. 几何着色器

用于执行逐图元的着色操作，或者用于产生更多图元，输入点、三角形等几何物体，输出点、线、三角形等几何物体

```glsl
// 爆炸效果的实现
#shader geometry
#version 330 core
layout(triangles) in;
layout(triangle_strip, max_vertices = 3) out;

in VS_OUT {
	vec2 g_TexCoord;
	vec3 g_Normal;
	vec3 g_FragPos;
} gs_in[];

out vec2 f_TexCoord;
out vec3 f_Normal;
out vec3 f_FragPos;

uniform float time;

vec4 explode(vec4 position, vec3 normal)
{
	float magnitude = 2.0;
	vec3 direction = normal * ((sin(time) + 1.0) / 2.0) * magnitude;
	return position + vec4(direction, 0.0);
}

vec3 GetNormal()
{
	vec3 a = vec3(gl_in[0].gl_Position) - vec3(gl_in[1].gl_Position);
	vec3 b = vec3(gl_in[2].gl_Position) - vec3(gl_in[1].gl_Position);
	return normalize(cross(a, b));
}

void main() {
	vec3 normal = GetNormal();

	gl_Position = explode(gl_in[0].gl_Position, normal);
	f_TexCoord = gs_in[0].g_TexCoord;
	f_Normal = gs_in[0].g_Normal;
	f_FragPos = gs_in[0].g_FragPos;
	EmitVertex();

	gl_Position = explode(gl_in[1].gl_Position, normal);
	f_TexCoord = gs_in[1].g_TexCoord;
	f_Normal = gs_in[1].g_Normal;
	f_FragPos = gs_in[1].g_FragPos;
	EmitVertex();
	
	gl_Position = explode(gl_in[2].gl_Position, normal);
	f_TexCoord = gs_in[2].g_TexCoord;
	f_Normal = gs_in[2].g_Normal;
	f_FragPos = gs_in[2].g_FragPos;
	EmitVertex();
	
	EndPrimitive();
}


// 法向量可视化
#version 330 core
layout (triangles) in;
layout (line_strip, max_vertices = 6) out;

in VS_OUT {
    vec3 normal;
} gs_in[];

const float MAGNITUDE = 0.4;

uniform mat4 projection;

void GenerateLine(int index)
{
    gl_Position = projection * gl_in[index].gl_Position;
    EmitVertex();
    gl_Position = projection * (gl_in[index].gl_Position + 
                                vec4(gs_in[index].normal, 0.0) * MAGNITUDE);
    EmitVertex();
    EndPrimitive();
}

void main()
{
    GenerateLine(0); // 第一个顶点法线
    GenerateLine(1); // 第二个顶点法线
    GenerateLine(2); // 第三个顶点法线
}
```



### 3. Early-Z

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1677807059843-b8bd15a7-5022-4bfa-81c8-f2cef5612707.png)

失效情况：

- 开启透明度测试、或者进行手动剔除片源
- 手动修改GPU插值得到的深度
- **开启透明度混合**（需要在一个像素上渲染多个图元）
- **关闭深度测试**



### 4. Z-PrePass

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1677811052552-3a4e55f8-83dd-49b5-81e8-b17b819af71c.png)

透明物体渲染背面的方法

有关透明物体的渲染



### 5. 实时渲染技术有哪些

- 实时阴影
- 实时全局光照
- 实时高质量着色
- 实时光追

### 6. 辐射度量学

![image-20231130111159733](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130111159733.png)

### 7. 渲染方程

某点以一定方向出射的radiance等于自发光的radiance+入射的各个方向的radiance*该点的brdf的和

![img](https://pic4.zhimg.com/v2-0d5ccb6c7c1e1b000524d152a91eb657_r.jpg)

### 8. PBR

[【基于物理的渲染（PBR）白皮书】（一） 开篇：PBR核心知识体系总结与概览 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/53086060)

- 是指使用基于物理原理和微平面理论建模的着色/光照模型，以及使用从现实中测量的表面参数来准确表示真实世界材质的渲染理念

- 基于物理的材质（Material）
- 基于物理的光照（Lighting）
- 基于物理适配的摄像机（Camera）

#### 8.1 基于物理的材质

- 基于微表面（Microfacet）的表面模型：微表面理论是将物体表面建模成**无数**微观尺度上有**随机朝向**的进行理想**镜面反射**的小**平面**的理论。从微观的角度观察着色物体表面，即任何表面都是一系列细微表面构成，光滑的物体其微表面朝向基本一致，粗糙的物体微表面朝向各不相同
- 能量守恒：对于入射光线，会发生反射和折射两种现象，反射对应的是specular，折射对应的是diffuse，反射率可以根据菲涅尔项计算得到，折射率通过1-反射率得到。
- 应用基于物理的BRDF：可以将brdf拆分成为漫反射和镜面反射两项，漫反射的brdf为一个常量，与物体表面材质的反射率也相关（注意区分材质的反射率c和菲涅尔项的反射率kd的区别：材质的反射率与材质本身的属性有关，通常表面为材质颜色，菲涅尔项的反射率与观察视角有关，垂直观察时反射率低，水平观察时反射率高，这也是球形物体外边缘发光的原因），在预计算中通常是针对各个方向构造半球进行采样实现，镜面反射的BRDF不是一个常量，它表现为FDG三个部分，其中F描述了物体的反射率、D描述了微表面法向量占半程向量的比例、G描述了自遮挡，在预先计算中分为两步，首先是计算平均光照，不能再像diffuse项那样对半球采样，而是采用重要性采样，只在一定的区域内采样计算积分，表面越光滑采样的区域越小，第二部分是计算BRDF，将基础反射率F0从渲染方程中提取出，将积分转换成关于入射方向和粗糙度的二维表达式，区分域与计算平均光照的积分域一致，也采用的是重要性采样。这样子只需要采样两张预计算的纹理（preFilter和LUT）即可完成积分计算

![image-20231130170640739](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130170640739.png)

- Fresnel公式的F0提出来，组成F0 * Scale +Offset的方式，再将Scale和Offset的索引存到一张2D LUT上。靠roughness和 NdotV进行查找
- 大多数电介质的基础反射率为0.04
- **注意大部分的采样都是需要转换到切线空间**

#### 8.2 BRDF

- BRDF，用来描述物体表面如何反射光线，通常拆分成漫反射和高光反射（因为纯镜面反射比较极端，一般考虑到高光反射中去）
- 其中漫反射的计算通常使用Lambert光照模型（经验模型）

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1680576708735-b3aa03de-a8d8-4289-9636-d84392080e8b.png)

- 高光反射：通常采用Phong模型和bllin-Phong模型，**渲染有时比Phong高光更柔和、更平滑**

  - Phong模型在处理高光时会出现光照不连续的情况。当光源和视点位于同一个方向时，反射光线跟观察方向可能大于90度，反射光线的分量就被消除了，会有颜色的跳变，所以出现高光不连续的现象


  ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1680577424296-64018317-3b37-4c35-8223-8092a55f0537.png?x-oss-process=image%2Fresize%2Cw_674%2Climit_0)

- Cook-Torrance反射率方程

  - 基于microfect微表面模型，将入射光分为反射和折射两部分，其中折射代表了diffuse，反射代表specular项


![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1680577621430-ccb6ac5f-6e94-468e-8f13-aa1d23dd7eb1.png)

![image-20231130112929869](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130112929869.png)

- NDF（法线分布函数）：Benchmark、GGX（更加平滑）、GTX（引入一个系数是的拖尾可控）

- **Microfacet BRDF**只考虑了光线在微表面一次bounce的情况，对于凹凸不平的粗糙表面会有能量损失，不满足能量守恒

- 使用**Kulla-Conty方法**近似补全丢失的能量，首先计算任意观察方向的能量顺势，通过将入射光设为1，对brdf进行积分得到出射能量，最后1-出射能量算出损失能量所占的百分比

  ![image-20231213155548249](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231213155548249.png)

![img](https://pic4.zhimg.com/80/v2-bc6f001ec6b46da195b317ad1c42b35f_720w.webp)

#### 8.3 线性变换的余弦（LTC）

我们需要把

1.**任意brdf的lobe变为固定的cos lobe**

2.我们需要所有的方向ωi进行变换,变为新的ωi',从而使得brdf的lobe变为固定的cos.

3.原本的多边形光源所覆盖的方向也需要进行变换,从而产生新的多边形光源覆盖的区域,然后我们再新的区域内对cos进行积分求出shading值.

![img](https://pic3.zhimg.com/80/v2-954b7a266d3aa3a5d47af3238baa23be_720w.webp)

通过变量替换的方法，使得任意BRDF会被替换为cos

LTC就是把 变化brdf 和 变化光源 通过线性变换 变成了在固定的brdf下变化的光源问题的一个方法.

#### 8.4 迪士尼原则的BxDF

引入原因：

- **微表面模型的效果虽然很好,但是不能表示出所有的材质,比如真实材质就无法表示**
- 微表面模型大多都不diffuse，不能描述多层的材质
- **微表面模型对艺术家来说并不好用**

各项属性：

- 将材质复杂的物理属性，用非常直观的少量变量表达了出来（如金属度metallic，粗糙度roughness，次表面反射subsurface，镜面反射specular，镜面反射的颜色specularTint、各项异性程度anisotropic）

![image-20231213162555917](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231213162555917.png)

- 金属没有折射，即没有漫反射，他们的基础反射是有一定颜色的，采用下面公式进行表示

![image-20231130165510200](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130165510200.png)

- 金属度越高，漫反射越弱，粗糙度越高漫反射越强

### 9. 渲染路径

#### 9.1 前向渲染路径

- 渲染每一帧，每个顶点/片元都要执行一次片元着色器代码，这时需要将所有的光照信息都传递到片元着色器中
- 尽管大部分情况下的光源都趋向于小型化，而且照亮的区域也不大，但是即使光源在世界空间中离物体的距离有多远，在计算光照的时候依然要将这个光源考虑进去

#### 9.2 延迟渲染路径

前向渲染存在的一个问题就是：当场景中包含大量实时光源时，每个光源都可能会被重复渲染多次，这就会造成程序性能急速下降。而延迟渲染就比较好地解决了这个问题，它充分利用了一个GBuffer的东西，将物体渲染的一些基本信息（比如法线、位置、深度、光照计算的材质属性等），都事先存储了起来，从而避免了大量的重复渲染计算。

GBuffer缓冲区包含以下几个渲染纹理对象：

- RT0：RGB通道存储漫反射，A通道不使用；
- RT1：RGB通道存储高光反射，A通道存储高光反射指数；
- RT2：RGB通道存储法线，A通道不适用；
- RT3：存储自发光、光照贴图和反射探针；
- Depth：存储深度缓冲和模板缓冲。

延迟渲染首先将物体的几何信息(位置、法线、颜色、镜面值）存到几何缓冲区中（即Geometric Buffer，G-Buffer）中，然后在光照处理阶段，使用G-Buffer中的纹理数据，对每个片段进行光照计算；这种渲染方法一个很大的好处就是能保证在G-Buffer中的片段和在屏幕上呈现的像素所包含的片段信息是一样的，因为深度测试已经最终将这里的片段信息作为最顶层的片段。这样保证了对于在光照处理阶段中处理的每一个像素都只处理一次。也就是说延迟渲染基本思想是，先执行深度测试，再进行着色计算，将本来在物体空间（三维空间）进行光照计算放到了屏幕空间（二维空间）进行处理，但这样做也导致计算光照的时候已经失去了模型的几何信息。

在每一帧当中G-buffer存储的信息有：位置、法线、颜色值、镜面值（所以其实有三张纹理，分别存位置、法线和颜色+镜面值(RGB+)A)；如果是PBR，应该还要再存一个金属度和粗糙度贴图。

#### 9.3 优缺点

- 前向渲染路径优点：支持半透明物体渲染，支持使用多个光照Pass，支持自定义光照计算（即每个物体可以单独计算光照，而延迟渲染全都写入G-buffer中，只能遵从一种光照计算）。
- 前向渲染路径缺点：光源数量对计算复杂度影响巨大，访问深度等数据需要额外计算。
- 延迟渲染路径优点：在有大量光照的场景优势显著，只渲染可见像素、节省计算量，对后处理支持良好，用更少的shader
- 延迟渲染路径缺点：对MSAA支持不友好，透明物体渲染存在问题，占用大量的显存带宽

#### 9.4 延迟渲染的改进

- 延迟光照 Light Pre-Pass（即Deferred Lighting）:star:
- 分块延迟渲染 Tile-BasedDeferred Rendering :star:

### 10. 几何着色器

- 输入一个图元（点或者三角形），在几何着色器中可以对其进行变换，也可以生成更多的图元。
- EmitVertex()、EndPrimitive()
- **可以用来法向量可视化Debug**

### 11. 曲面细分着色器:star:

### 12. gamma校正和HDR

- gamma校正：显示器对于颜色的输出有一个2.2次方的校正，为了适应人眼，但在实际操作中，我们计算的颜色值都是在线性空间下进行的，因此在计算出颜色值之后，还需要将其进行校正，确保输出到显示器的结果是我们想要的
- hdr：色调映射，采用浮点精度存放颜色属性，使得可以表示更高范围的颜色值，防止大于1的颜色值被截断，注意在计算完成之后，还需要通过gamma校正，将线性空间下计算的数值转换到非线性空间下供显示器输出
- Bloom：使用MRT获得一张普通渲染图和一张高光区域的渲染图，对高光区域的渲染图进行模糊，再将两张渲染图进行叠加

### 13. GPU与CPU的区别

- CPU：少量性能强劲的运算单元进行复杂运算
- GPU：大量性能较弱的运算单元进行简单运算

### 14. DrawCall

- 就是CPU调用图像应用编程接口，来命令GPU进行渲染的操作。CPU通过图像编程接口向命令缓冲区中添加命令，而GPU从中读取命令并执行。蓝色方框内的命令就是Draw Call，而红色方框内的命令用于改变渲染状态。我们使用红色方框来表示改变渲染状态的命令，是因为这些命令往往更加耗时。

![img](https://pic2.zhimg.com/80/v2-dc34c7c2b589ac6ccbd54a3224390f91_720w.webp)

- 减少DrawCall的方法
  - 批处理：动态批处理在每一帧都对使用相同material的物体进行mesh合并，通过一次DrawCall实现绘制，对顶点的规模有要求。静态批处理物体无法移动，也是通过合并减少DrawCall次数。
  - 共享材质：将纹理合并成大纹理，并在顶点属性中添加相关的纹理采样缩放和偏移实现。

### 15. 漫反射为什么要除以Π

- 能量守恒：考虑一根光线打到Diffuse物体表面沿着各个方向均匀分散，Radicance和BRDF都是常量提取出来，对Cos积分是Π，那为了能量守恒，就要除以Π

![在这里插入图片描述](https://img-blog.csdnimg.cn/7f950d38eaf64b0aa57d8c8bc5cda2d9.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p-z5LiJ5Y-2,size_17,color_FFFFFF,t_70,g_se,x_16#pic_center)

### 16. 光照模型

#### 16.1 局部光照模型

- phong模型和Blin-phong模型：环境光为常量、漫反射分量（与光照方向和物体表面法线的夹角有关）、镜面反射分量（与观察方向和出射方向的夹角有关）
- cook-torrance
- Phong氏光照模型其实是经验模型，参数信息是通过经验得到的。Phong模型将物体光照分为三个部分进行计算，分别是：漫反射分量、镜面高光和环境光。其中，环境光分量是用来模拟全局光照效果的，其实就是在物体光照信息基础上叠加上一个较小的光照常量，用来表示场景中其他物体反射的间接光照。具体实现：环境分量，直接设置一个ambient分量，乘上光照颜色和物体颜色；漫反射分量，用光线到片段的向量与片段平面法线向量的点乘，乘上光的颜色和物体颜色；镜面分量，通过指数函数pow计算，有一个shininess分量，越大表示高光越尖锐，用到了视线方向和反射光线方向的点积。
- Blinn-Phong氏光照模型是对Phong氏光照模型的改进，Phong模型在处理高光时会出现光照不连续的情况。当光源和视点位于同一个方向时，反射光线跟观察方向可能大于90度，反射光线的分量就被消除了，所以出现高光不连续的现象。Blinn-Phong模型在处理镜面反射时不使用观察方向和反射光线的夹角来计算，而是引入了一个新的向量：**半角向量(Halfway vector)**。半角向量其实很简单，就是入射光线向量L和观察方向V的中间位置（角平分线）。Blinn-Phong求高光亮度的时候使用半角向量和法向量的点积来决定高光亮度。Phong是用反射光线和视线向量的点积来求高光亮度。

#### 16.2 全局光照模型

- 路径追踪：对于每个交点只投射一根光线，存在很大的噪点

  - 噪点解决方法：使用多条光线穿过像素，光线在环境中弹射，最后连接到光源(视点)，产生了一条路径，所以我们叫路径追踪。对于每一个像素，要发出一系列的光线，然后在任何一个打到的点上，要把这个着色的结果求平均然后算出来。

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/ab4f9cf95653414b9082fe9132d61df2.png#pic_center)

  - 递归终止：俄罗斯轮盘赌，对于每个交点，都有P的概率发射光线，最后得到的结果要除以p

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/29d7ad2c82f849528b120f3ec8b68eef.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p-z5LiJ5Y-2,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

  - 对于每一个屏幕发出的射线与物体的交点，先判断是否可见，如果可见则在光源上进行采样（pdf为1/A），然后再往四面八方随机以俄罗斯轮盘赌的形式发射一根光线如果与物体有交点则递归这一过程（1/2pi * 1 / PRR）

- 分布式光线追踪：对于每个交点投射的光线数量不唯一

- Whitted-Style光线追踪：从视点向成像平面上的像素发射光线，找到与该光线相交的最近物体的交点，如果该点处的表面是散射面，则计算光源直接照射该点产生的颜色；如果该点处表面是镜面或折射面，则继续向反射或折射方向跟踪另一条光线，如此递归下去，直到光线逃逸出场景或达到设定的最大递归深度。

  - 问题：只考虑了镜面反射没有考虑漫反射，对于glossy和diffuse物体效果不佳

### 17. 光线追踪

#### 17.1 光线与三角形求交

- 光线与平面求交，再判断交点是否在三角形内（叉乘）
- 根据三角形重心坐标构造平面表达式，然后还是一样求解光线与平面相交的方程，得到三个重心权重必须为大于0小于1的

![在这里插入图片描述](https://img-blog.csdnimg.cn/2cf49c2e24b1419e97c71a2f59c5b122.png#pic_center)

####  17.2 光线与物体求交

- AABB轴对齐包围盒
- 分别求进入和离开三对平面的时间，取进入时间的最大值和离开时间的最小值得到进入和离开包围盒的时间，如果进入时间小于离开时间则说明光线有一段时间实在包围盒内部，由于光线是一条射线，还需要判断离开时间是否大于0

#### 17.3 光线与场景求交

- 空间划分

  - 均匀空间划分

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/199f8a46cf8242a284be74b8b02b1b18.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p-z5LiJ5Y-2,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

  - 不均匀空间划分

  ![在这里插入图片描述](https://img-blog.csdnimg.cn/4953420c1d0c4b43bb277c9bba92f598.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5p-z5LiJ5Y-2,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center)

  Oct-Tree：八叉树（在二维情况下是四叉树），把空间中一个大的包围盒切成八份（横竖平三刀切成八份），对于每一个子节点都再切成八块，当每个盒子中有足够少数量的物体则停止切割。但是维度高不好计算。上图中就对一个大块进行了细分，事实上对每一个放个都需要进行细分切割。
  KD-Tree：每次划分只沿着一条轴砍一刀，分成两块。竖直切割和水平切割在树的层次中交替。划分有点像二叉树，但是划分并不平均。例：第一层一个节点水平分割，第二层两个节点竖直分割。
  BSP-Tree：二分法，每次选一个方向将空间分割开。相较于KD-Tree，每次切一刀不限于坐标轴方向，可以为任意方向，只要将空间切为两个部分即可 。

  KD-Tree的不足：一个物体可能出现在多个叶子节点中，很难判断三角形与盒子是否相交。

- 物体划分BVH

  - 将物体两堆两堆地划分下去，每一次划分完成都需要计算其包围盒，不同包围盒可以相交。找到一个包围盒，递归地把一个包围盒拆成两个部分（通过把包围盒里的物体分成两个部分），把这两个新拆出来的两个部分重新计算他们的包围盒，在必要的时候停下来(当节点包含很少的元素时停止)，在每一个叶子节点中存储实际物体
  - 如何划分节点：总是选择最长的轴来进行划分，让最长的轴变短，通过这种方式最后能变成一种比较均匀的状态；选择中间的物体作为划分。这样可以让划分的两个部分包含的物体差不多相等。
  - 中间节点的存储：包围盒、子节点指针
  - 叶子节点的存储：包围盒、包含的物体

  ![image-20231130203559205](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130203559205.png)

- 基于空间的划分包围盒之间没有空间上的overlap，但是一个物体可能存在多个叶子节点中，且物体是否再包围盒内的判断较难，基于物体的划分包围盒之间存在空间上的overlap，但是物体只在一个叶子节点中。

### 18. 蒙特卡洛积分

![image-20231130204321502](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130204321502.png)

### 19. 环境遮蔽（SSAO）

三个假设：

- 由于我们不知道间接光照是什么，因此我们假设任何一个**shading point**上来自**任何方向**的**间接光照**(incident lighting)是一个**常数**.
- 虽然我们考虑了任何一个**shading point**上来自**任何方向**的**间接光照**是一样的,但并不是每个方向都可能接收到间接光照(incident lighting)，也就是不同位置的Visibility是不同的。
- 假设物体是Diffuse的,即使是一个glossy物体我们也以diffuse去渲染

具体步骤：

- 在角落或者坑坑洼洼的地方，存在遮挡，光线进去之后出不来会较暗
- 首先生成一系列采样点（这些采样点分布在一个靠近原点的半球中）
- 然后创建一张旋转纹理，里面存放了大量定义在切线空间的旋转向量，这些旋转向量绕着Z轴旋转
- 第一个Pass计算屏幕上各个像素位于观察空间的位置、法向量
- 第二个Pass针对各个像素点进行半球空间的采样，比较深度值计算遮挡因子（这里为了防止不正确的计算遮挡对被测深度值的范围做了限制）
- 为了减少噪声，在第三个Pass进行了遮挡贴图的模糊
- 第四个Pass计算光照，并在环境光分量上乘上遮挡因子

进阶版本：SSDO（Screen space direction occlusion）

比起AO考虑间接光照是一个常数,在DO里我们更精确的考虑了间接光照

- AO：在AO中我们认为红色的框里能接收间接光照，黄色框里无法接收间接光照，然后求出加权平均的visibility值,也就是**假设间接光照是从比较远的地方来的**；

- DO：在DO中,我们认为红色框里接收的是直接光照,而黄色框里才是接收到的间接光照.因为红色框里的光线打不到用来反射的面，因此这些方向上就不会有间接光照，黄色框里的光线能打到物体上，P点接收到的是来自红色框的**直接光照**+黄色框里的**间接光照**,也就是**假设间接光照是从比较近的反射物来的。**

![img](https://pic2.zhimg.com/80/v2-dbca00b5365d0cc8fb54483f92234dc5_720w.webp)

- 缺点：
  - 可能会有一些间接光照的点计算不到
  - P点对于半球上的点可见性是通过Camera对这些点的可见性来近似计算的，存在于屏幕空间中丢失信息的问题，下图是一个很明显的例子，当黄色的面朝向屏幕的时候地面的SSDO信息是正确的，而当旋转过去之后，就看不到SSDO的信息了。
  - SSDO只能解决一个很小范围内的全局光照，下图是接近正确的情况，而如果使用SSDO来计算，方块右边是追踪不到远处绿色的墙的，方块上也就不会有绿色的反光。

### 20. 计算线性深度

- 一个线性深度在经过投影变换到NDC空间之后就变得不再线性了，所有物体都会被推向远端，反应在深度图上就是大部分颜色为白色，为了得到线性的深度图，需要对深度进行变换。

![image-20231130231329087](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130231329087.png)

![img](https://learnopengl-cn.github.io/img/04/01/depth_non_linear_graph.png)

![image-20231203212713636](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231203212713636.png)

### 21. TBN矩阵

- 切线空间的法向量一直是【0, 0, 1】
- 切线空间的切线向量（T）可以根据顶点坐标和纹理坐标得到

![img](https://learnopengl-cn.github.io/img/05/04/normal_mapping_surface_edges.png)

- 解方程两个顶点的位置的差=纹理坐标x的差  * T + 纹理坐标y的差 * B
- 这里求出来的T和B是位于模型空间的（因为顶点坐标位于模型空间），可以通过model矩阵变换到世界空间

### 22. 法向量不等比缩放:star:

![image-20231212214308739](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231212214308739.png)

- 对于没有逆矩阵的矩阵，还可以使用伴随矩阵

![image-20231212214705777](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231212214705777.png)

### 23. MipMap多级渐进纹理

#### 23.1 基本原理 

- 在一个场景内有很多物体，有的远有的近。远处的物体只占很少的片段（假设每个物体都有各自的纹理，且分辨率都很高的话），此时如果要从高分辨率的纹理中采样，会比较困难，因为一个很小的物体，一个像素映射到纹理上会占据很大一块，包含了很多个纹理像素，不好采样，因此引出了多级渐远纹理(mipmap)技术。
- 将纹理划分为不同大小分辨率的纹理图集，每次缩小1/2划分，根据物体的大小，来对不同级别的纹理进行采样。对远处的物体，采用低分辨率的纹理，对于近处的物体，采用高分辨率的纹理。简单讲就是根据距离摄像机的远近来决定采样相对层级的纹理

#### 23.2 如何确定采样哪一级

- 对于每一个像素点，找他相邻的上方和右方的像素点，得到在uv空间下的坐标位置，这样就可以得到屏幕空间一个像素的偏移相当于切线空间多长的距离，然后取log得到对应的mipmap层级

### 24.  各种贴图的作用

#### 24.1 凹凸贴图

-   凹凸贴图是指计算机图形学中在三维环境中通过纹理方法来产生表面凹凸不平的视觉效果。它主要的原理是通过改变表面光照方程的法线，而不是表面的几何法线，或对每个待渲染的像素在计算照明之前都要加上一个从高度图中找到的扰动，来模拟凹凸不平的视觉特征，如褶皱、波浪等等。

#### 24.2 移位贴图

- 移位贴图，也有人称为置换贴图，或称高度纹理贴图（Heightfield Texturing）。这种方法类似于法线贴图，移位贴图的每一个纹素中存储了一个向量，这个向量代表了对应顶点的位移。注意，此处的纹素并不是与像素一一对应，而是与顶点一一对应，因此，纹理的纹素个数与网格的顶点个数是相等的。在VS阶段，获取每个顶点对应的纹素中的位移向量，（注意，直到3.0版本的vs才支持纹理数据的获取，之前的版本只有ps才能获取纹理数据），施加到局部坐标系下的顶点上，然后进行世界视点投影变换即可
  - 置换顶点有一个问题就是平面必须由很多顶点组成才能获得具有真实感的效果，否则看起来效果并不会很好。一个平坦的表面上有1000个顶点计算量太大了。我们能否不用这么多的顶点就能取得相似的效果呢？事实上，上面的表面就是用6个顶点渲染出来的（两个三角形）。上面的那个表面使用视差贴图技术渲染，位移贴图技术不需要额外的顶点数据来表达深度，它像法线贴图一样采用一种聪明的手段欺骗用户的眼睛

#### 24.3 法线贴图

-   法线贴图（Normal mapping）是凸凹贴图（Bump mapping）技术的一种应用，法线贴图有时也称为“Dot3（仿立体）凸凹纹理贴图”。凸凹与纹理贴图通常是在现有的模型法线添加扰动不同，法线贴图要完全更新法线。与凸凹贴图类似的是，它也是用来在不增加多边形的情况下在浓淡效果中添加细节。但是凸凹贴图通常根据一个单独的灰度图像通道进行计算，而法线贴图的数据源图像通常是从更加细致版本的物体得到的多通道图像，即红、绿、蓝通道都是作为一个单独的颜色对待。

#### 24.4 视差贴图

-   :star:视差贴图Parallax Mapping，又称为 Offset Mapping，以及virtual displacement mapping)，于2001年由Kaneko引入，由Welsh进行了改进和推广。视差贴图是一种改进的Bump Mapping技术，相较于普通的凹凸贴图，视差贴图技术得到凹凸效果得会更具真实感（如石墙的纹理将有更明显的深度）。**视差贴图是通过替换渲染多边形上的顶点处的纹理坐标来实现的，而这个替换依赖于一个关于切线空间中的视角（相对于表面法线的角度）和在该点上的高度图的方程。简单来说，Parallax Mapping利用Height Map进行了近似的Texture Offset**。如图 

![img](https://cdn.nlark.com/yuque/0/2023/webp/29680306/1689225296141-326409a6-9293-4a7e-95d1-e3da0d5f704e.webp?x-oss-process=image%2Fresize%2Cw_750%2Climit_0)

### 25. 抗锯齿技术

- 在每个像素中进行多次采样，然后根据多次采样的结果综合来计算像素的颜色值。使用这种方式来实现的抗锯齿技术有MSAA，TAA。

-  通过后处理的方式，寻找屏幕中的像素块边界，然后根据边界的信息，将两侧的像素点颜色进行插值，这样就会得到平滑过渡的边缘，实现抗锯齿的效果。使用这种方式来实现的抗锯齿技术有FXAA，SMAA。

#### 25.1 SSAA

#### 25.2 MSAA

- 为什么延迟渲染不能用MSAA

- - MSAA本质上是一种发生在光栅化阶段的技术，也就是几何阶段后，着色阶段前，用这个技术需要用到场景中的几何信息
  - 延迟渲染因为需要节省光照计算的原因，事先把所有信息都放在了GBuffer上，着色计算的时候已经丢失了几何信息（三角形的边信息）

#### 25.3 TAA

- 分别在不同帧选用不同的采样点，结合各个帧的结果
- **也就是通过将前N帧内的样本点的结果平均起来，其效果与在当前帧内增加样本点的效果一样。**

#### 25.4 FXAA

- 边缘检测：对SceneColor贴图进行边缘数据判定，这里的判定规则不是color，而是基于color换算得到的luma，因此可以检测出包含高光、阴影、几何边缘、半透物体在内的多种着色锯齿，从而使得其抗锯齿效果要优于MSAA（只支持几何锯齿）
- 边缘混合：针对边缘像素，对SceneColor进行相邻像素采样混合，采样数目越多，抗锯齿效果越好，但是消耗也越高。
- FXAA：基于图像域的抗锯齿技术，首先计算五个点的最大和最小亮度，当亮度差距大于预设置的阈值的时候，则判定该点位于边界位置，对于位于边界位置的点，采用周围3X3也就是8个点计算其平均亮度（使用不同的权值），根据周围8个点的平均亮度和中间点的亮度之差计算混合因子，得到混合因子之后还需要计算混合方向，方法是沿着水平方向和垂直方向分别计算亮度差，亮度差更大的是方向，然后根据权重进行偏移得到最终结果。
- 观察抗锯齿之后的效果，我们发现，斜向的锯齿，AA效果其实不太好。
  这是因为我们其实只是根据目标像素点周围 3X3 的像素点进行采样分析，并且假设锯齿边界是完全垂直或者水平的，但是很多时候，我们的锯齿边界是带有角度的。这样，要得到得到正确的混合系数，就需要将采样范围扩展到 3X3 像素块之外，求出锯齿边界的倾斜角度。比如下图中的理想抗锯齿效果，就需要进行额外的采样。
- 找锯齿边界，根据距离边界的远近得到相应的混合系数
- FXAA 的优点就是集成比较方便，只需要一个 Pass 来实现抗锯齿，同时提供了两个版本，可根据情况灵活选用，是目前手机上的最常用的抗锯齿方式。
- FXAA的缺点是画面会略微有些模糊。而且由于FXAA是基于后处理判断边界来实现的，因此没有次像素特性，在光照高频(颜色变化很快)的地方会不稳定。单独看静态的场景没有问题，但是移动摄影机时，就会导致一些闪烁。

### 26. 降噪算法

- 

### 27. 后处理算法

#### 27.1 动态模糊

- 混合多张连续图像
  - 将上一帧的结果保留与这一帧进行混合，并将混合结果作为输入给下一帧用
- 速度映射
  - 先得到当前帧的NDC坐标（z值通过深度缓冲得到），通过VP矩阵的逆得到在世界空间下的坐标，再通过上一帧的VP矩阵得到当前位置在上一帧的哪个位置，然后将当前位置和上一帧的位置的着色进行混合。

#### 27.2 泛光

- MRT技术，渲染一张普通贴图和一张只包含高量信息的贴图
- 高亮信息贴图做模糊
- 两张图做混合

#### 27.3 边缘检测

- 基于法线
  - 观察方向向量和着色表面法线向量点乘,如果得到的值接近于0,说明着色区域是contour edges.
  - 缺点：对于法线分布不均匀和一些类似正方体的模型上会失败
- 基于几何
  - 把模型加大一圈,然后大模型放在原模型背后并且把新模型完全渲染成黑,就像你背后站了一个就比宽一点高一点的替身使者,但这个替身使者是全黑的,这不就是描边了吗.
  - 封闭模型正面和背面所能看到的区域是完全一样的,也就是看不到模型背面的任何信息,因此我们将模型背面给扩大一圈,也就是把背面的每个三角形扩大了一圈,并渲染成黑色,从而得到描边的效果.
  - 缺点：需要将整个背部的面都渲染,所以这种方式可能造成一些资源浪费.对于半透明物体的渲染描边,也会产生影响.

- 卷积核Sobel

  - 计算亮度值的梯度，梯度大于预设值的即为边缘

  - 在利用lerp函数进行插值
  - 缺点：阴影、纹理也会被计算为边缘

- Roberts算子

  - 计算对角线上像素点深度和法线差异，差异大说明为边界

#### 27.4 调整屏幕亮度、饱和度和对比度

#### 27.5 全局雾效

- 根据NDC空间的深度，计算出世界空间下的深度，然后再根据顶点着色器平面四个角的射线插值出位移向量，最终与世界空间下相机坐标相加得到世界空间的位置

![image-20231207110740653](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231207110740653.png)

![image-20231207110757514](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231207110757514.png)

![image-20231207110726541](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231207110726541.png)

#### 27.6 物体轮廓

步骤：

- 在绘制（需要添加轮廓的）物体之前，将模板函数设置为GL_ALWAYS，每当物体的片段被渲染时，将模板缓冲更新为1
- 渲染物体
- 禁用模板写入以及深度测试
- 将每个物体缩放一点点
- 使用一个不同的片段着色器，输出一个单独的（边框）颜色
- 再次绘制物体，但只在它们片段的模板值不等于1时才绘制

### 28. 非真实感渲染

#### 28.1 卡通风格渲染

#### 28.2 素描风格渲染

### 29. Computer Shader

- 函数声明`#pragma kernel xxx`

- 变量定义

```cpp
RWTexture2D<float4> Result1;
RWBuffer Result2;

struct ParticleData {
	float3 pos;
	float4 color;
};
RWStructuredBuffer<ParticleData> ParticleBuffer;
```

- 线程定义

```cpp
numthreads(tX, tY, tZ)
```

- 线程调用

![image-20231204231446155](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231204231446155.png)

- 调用端

```csharp
// 传输数据
public struct ParticleData
{
    public Vector3 pos;//等价于float3
    public Color color;//等价于float4
}

//struct中一共7个float，size=28
mParticleDataBuffer = new ComputeBuffer(mParticleCount, 28);
ParticleData[] particleDatas = new ParticleData[mParticleCount];
mParticleDataBuffer.SetData(particleDatas);
kernelId = computeShader.FindKernel("UpdateParticle");

computeShader.SetBuffer(kernelId, "ParticleBuffer", mParticleDataBuffer);
computeShader.SetFloat("Time", Time.time);
computeShader.Dispatch(kernelId,mParticleCount/1000,1,1);

// 定位核函数
int kernelIndex = computeShader.FindKernel("CSMain");
// 调用核函数
computeShader.Dispatch(kernelIndex, 256 / 8, 256 / 8, 1);
```

- 动态改变数组

```csharp
var buffer = new ComputeBuffer(count, sizeof(float), ComputeBufferType.Append);
buffer.SetCounterValue(0);//计数器值为0

// 获取长度
uint[] countBufferData = new uint[1] { 0 };
var countBuffer = new ComputeBuffer(1, sizeof(uint), ComputeBufferType.IndirectArguments);
ComputeBuffer.CopyCount(buffer, countBuffer, 0);
countBuffer.GetData(countBufferData);

// shader端
AppendStructuredBuffer<float> result;

[numthreads(640, 1, 1)]
void ViewPortCulling(uint3 id : SV_DispatchThreadID)
{
    if(满足一些自定义条件)
        result.Append(value);
}
```

- Shader.proertyToID

```csharp
int grassMatrixBufferId;
void Start() {
    grassMatrixBufferId = Shader.PropertyToID("grassMatrixBuffer");
}
void Update() {
    compute.SetBuffer(kernel, grassMatrixBufferId, grassMatrixBuffer);
    
    // dont use it
    //compute.SetBuffer(kernel, "grassMatrixBuffer", grassMatrixBuffer);
}
```

- Shader variants and keywords

```glsl
#pragma kernel CSMain
#pragma multi_compile __ COLOR_WHITE COLOR_BLACK

RWTexture2D<float4> Result;

[numthreads(8,8,1)]
void CSMain (uint3 id : SV_DispatchThreadID)
{
#if defined(COLOR_WHITE)
	Result[id.xy] = float4(1.0, 1.0, 1.0, 1.0);
#elif defined(COLOR_BLACK)
	Result[id.xy] = float4(0.0, 0.0, 0.0, 1.0);
#else
	Result[id.xy] = float4(id.x & id.y, (id.x & 15) / 15.0, (id.y & 15) / 15.0, 0.0);
#endif
}

public class DrawParticle : MonoBehaviour
{
    public ComputeShader computeShader;

    void Start() {
        ......
        computeShader.EnableKeyword("COLOR_WHITE");
    }
}
```

### 30. GLSL语法

```glsl
#shader vertex
#version 330 core
layout(location = 0) in vec4 position;
layout(location = 1) in vec3 normal;
layout(location = 2) in vec2 texCoord;

out VS_OUT{
	vec2 TexCoord;
	vec3 Normal;
	vec3 FragPos;
} vs_out;

uniform mat4 projection;
uniform mat4 view;
uniform mat4 model;

void main() {
	vs_out.TexCoord = texCoord;				// 传递纹理坐标
	vs_out.FragPos = vec3(model * position);	// 计算出世界坐标系下的片段位置
	vs_out.Normal = mat3(transpose(inverse(model))) * normal;	// 计算不等比缩放时的法向量
	gl_Position = projection * view * vec4(vs_out.FragPos, 1.0);

}

#shader fragment
#version 330 core

in VS_OUT{
	vec2 TexCoord;
	vec3 Normal;
	vec3 FragPos;
} fs_in;

// 材料属性参数
uniform vec3  albedo;
uniform float metallic;
uniform float roughness;
uniform float ao;

// IBL
uniform samplerCube irradianceMap;
uniform samplerCube prefilterMap;
uniform sampler2D brdfLUT;

// 光源属性
uniform vec3 lightPositions[4];
uniform vec3 lightColors[4];

uniform vec3 camPos;
const float PI = 3.14159265359;

out vec4 FragColor;

// 法线分布函数（估算在受到表面粗糙度影响下，朝向方向与半程向量一致的微平面数量）
// 主要影响粗糙度
float DistributionGGX(vec3 N, vec3 H, float roughness)
{
	float a = roughness * roughness;
	float a2 = a * a;
	float NdotH = max(dot(N, H), 0.0);
	float NdotH2 = NdotH * NdotH;

	float nom = a2;
	float denom = (NdotH2 * (a2 - 1.0) + 1.0);
	denom = PI * denom * denom;

	return nom / denom;
}

float GeometrySchlickGGX(float NdotV, float roughness)
{
	float r = (roughness + 1.0);
	float k = (r*r) / 8.0;

	float nom = NdotV;
	float denom = NdotV * (1.0 - k) + k;

	return nom / denom;
}

// 几何函数（描述微平面自成阴影的属性）
// 将观察方向，光线方向，粗糙度考虑进去
// 主要影响亮度
float GeometrySmith(vec3 N, vec3 V, vec3 L, float roughness)
{
	float NdotV = max(dot(N, V), 0.0);
	float NdotL = max(dot(N, L), 0.0);
	float ggx2 = GeometrySchlickGGX(NdotV, roughness);
	float ggx1 = GeometrySchlickGGX(NdotL, roughness);

	return ggx1 * ggx2;
}

// 菲涅尔方程（是在不同表面角下表面所反射的光线所占的比率）
// 观察方向与法线的角度，材质属性
vec3 fresnelSchlick(float cosTheta, vec3 F0)
{
	return F0 + (1.0 - F0) * pow(clamp(1.0 - cosTheta, 0.0, 1.0), 5.0);
}

vec3 fresnelSchlickRoughness(float cosTheta, vec3 F0, float roughness) {
	return F0 + (max(vec3(1.0 - roughness), F0) - F0) * pow(clamp(1.0 - cosTheta, 0.0, 1.0), 5.0);
}

void main() {
	vec3 N = normalize(fs_in.Normal);
	vec3 V = normalize(camPos - fs_in.FragPos);
	vec3 R = reflect(-V, N);

	// 面对大多数绝缘体，F0为0.04，如果是金属则会发生变色
	vec3 F0 = vec3(0.04);
	F0 = mix(F0, albedo, metallic);

	// 反射率计算
	vec3 Lo = vec3(0.0);
	for (int i = 0; i < 4; ++i) {
		vec3 L = normalize(lightPositions[i] - fs_in.FragPos);	// 计算每个光线的辐射
		vec3 H = normalize(V + L);	// 计算半程向量

		float distance = length(lightPositions[i] - fs_in.FragPos);	// 计算光源与待计算片段的位置
		float attenuation = 1.0 / (distance * distance);
		vec3 radiance = lightColors[i] * attenuation;

		float NDF = DistributionGGX(N, H, roughness);	// 计算法线分布函数
		float G = GeometrySmith(N, V, L, roughness);	// 计算几何函数
		vec3 F = fresnelSchlick(clamp(dot(H, V), 0.0, 1.0), F0);	// 计算菲涅尔方程

		vec3 numerator = NDF * G * F;
		float denominator = 4 * max(dot(N, V), 0.0) * max(dot(N, L), 0.0) + 0.0001; // + 0.0001 to prevent divide by zero
		vec3 specular = numerator / denominator;

		// Ks等于菲涅尔
		vec3 kS = F;

		// 为了保持能量守恒，漫反射和镜面反射不能高于1.0(除非表面发光)
		// 所以漫反射分量（KD）等于1.0 - Ks
		vec3 kD = vec3(1.0) - kS;

		// Kd乘以金属度，这样只有非金属才有漫反射，或者部分金属有线性混合（纯金属没有漫反射）
		kD *= 1.0 - metallic;

		float NdotL = max(dot(N, L), 0.0);

		// 将该光源计算得到的反射率累加到该片段的总反射率中
		// 漫反射分量+镜面光分量
		Lo += (kD * albedo / PI + specular) * radiance * NdotL;	// 因为已经将BRDF乘以菲涅尔KS，因此不需要再乘以KS
	}

	// 计算环境光中漫反射分量
	// vec3 ambient = vec3(0.03) * albedo * ao;
	// IBL diffuse部分
	vec3 F = fresnelSchlickRoughness(max(dot(N, V), 0.0), F0, roughness);
	vec3 kS = F;
	vec3 kD = 1.0 - kS;
	kD *= 1.0 - metallic;

	vec3 irradiance = texture(irradianceMap, N).rgb;
	vec3 diffuse = irradiance * albedo;

	// 对预过滤贴图和BRDF进行采样，并根据Split-Sum近似将他们组合一起 获取IBL镜面反射部分
	const float MAX_REFLECTION_LOD = 4.0;
	vec3 prefilteredColor = textureLod(prefilterMap, R, roughness * MAX_REFLECTION_LOD).rgb;
	vec2 brdf = texture(brdfLUT, vec2(max(dot(N, V), 0.0), roughness)).rg;
	vec3 specular = prefilteredColor * (F * brdf.x + brdf.y);

	vec3 ambient = (kD * diffuse + specular) * ao;

	vec3 color = ambient + Lo;

	// HDR 色调映射
	color = color / (color + vec3(1.0));
	// gamma 校正
	color = pow(color, vec3(1.0 / 2.2));

	FragColor = vec4(color, 1.0);
}

```

###  31. HLSL语法

```glsl
#include "ShaderCommon/Transform.hlsli"
#include "ShaderCommon/VShadow.hlsli"

struct VSOut
{
    float3 viewPos : Position;
    float3 viewNormal : Normal;
    float3 tan : Tangent;
    float3 bitan : Bitangent;
    float2 tc : Texcoord;
    float4 shadowHomoPos : ShadowPosition;
    float4 pos : SV_Position;
};

VSOut main(float3 pos : Position, float3 n : Normal, float2 tc : Texcoord, float3 tan : Tangent, float3 bitan : Bitangent)
{
    VSOut vso;
    vso.viewPos = (float3) mul(float4(pos, 1.0f), modelView);
    vso.viewNormal = mul(n, (float3x3) modelView);
    vso.tan = mul(tan, (float3x3) modelView);
    vso.bitan = mul(bitan, (float3x3) modelView);    
    vso.pos = mul(float4(pos, 1.0f), modelViewProj);
    vso.tc = tc;
    vso.shadowHomoPos = ToShadowHomoSpace(pos, model);
    return vso;
}
```

```glsl

#include "ShaderCommon/PointLight.hlsli"
#include "ShaderCommon/Pshadow.hlsli"

cbuffer ObjectCBuf : register(b1)
{
    float3 specularColor;
    float specularWeight;
    float specularGloss;
    bool useNormalMap;
    float normalMapWeight;
};

Texture2D tex : register(t0);
Texture2D nmap : register(t2);
SamplerState splr : register(s0);

float4 main(float3 viewFragPos : Position, float3 viewNormal : Normal, float3 viewTan : Tangent, float3 viewBitan : Bitangent, float2 tc : Texcoord, float4 spos : ShadowPosition) : SV_Target
{
    float3 diffuse;
    float3 specular;
    
    // shadow map test
    const float shadowLevel = Shadow(spos);
    if (shadowLevel != 0.0f)
    {
        // normalize the mesh normal
        viewNormal = normalize(viewNormal);
        // replace normal with mapped if normal mapping enabled
        if (useNormalMap)
        {
            const float3 mappedNormal = MapNormal(normalize(viewTan), normalize(viewBitan), viewNormal, tc, nmap, splr);
            viewNormal = lerp(viewNormal, mappedNormal, normalMapWeight);
        }
	    // fragment to light vector data
        const LightVectorData lv = CalculateLightVectorData(viewLightPos, viewFragPos);
	    // attenuation
        const float att = Attenuate(attConst, attLin, attQuad, lv.distToL);
	    // diffuse
        diffuse = Diffuse(diffuseColor, diffuseIntensity, att, lv.dirToL, viewNormal);
        // specular
        specular = Speculate(
            diffuseColor * diffuseIntensity * specularColor, specularWeight, viewNormal,
            lv.vToL, viewFragPos, att, specularGloss
        );
        // scale by shadow level
        diffuse *= shadowLevel;
        specular *= shadowLevel;
    }
    else
    {
        diffuse = specular = 0.0f;
    }
	// final color
    return float4(saturate((diffuse + ambient) * tex.Sample(splr, tc).rgb + specular), 1.0f);
}
```

### 32. ECS系统

- 实体

实体只是一个概念上的定义，指的是存在你游戏世界中的一个独特物体，是一系列组件的集合。为了方便区分不同的实体，在代码层面上一般用一个ID来进行表示。所有组成这个实体的组件将会被这个ID标记，从而明确哪些组件属于该实体。

- 组件

一个组件是一堆数据的集合，可以使用结构体来进行实现。相机组件、位置组件、渲染组件、脚本组件等，没有方法

- 系统

ECS架构中用来处理逻辑的部分，包含了如何对组件进行操作

- 优点：对缓存友好，提高程序执行效率
- 缺点：不利于维护

### 33. 软阴影

#### 33.1 自遮挡解决方法

- bias（根据光照方向和平面的夹角确定bias的大小）
- 存储第二深的深度，比较的时候用深度的平均值
- 先剔除物体正面，然后渲染阴影图（将自遮挡问题反映在物体内部）
- 减少沿着光照方向渲染阴影贴图使用的光照空间范围，提高阴影贴图的精度
- 使用级联阴影，根据着色点距离相机的远近使用不同的阴影图

#### 33.2 PCF 

![img](https://pic4.zhimg.com/80/v2-87711d613321b2c2201416e2d8f5556b_720w.webp)

- 在判断可见性的时候，不止在深度图上取单一像素作比较，而是取一定范围内的像素作比较

#### 33.3 PCSS

- 在点p附近取一个范围(这个范围是自己定义或动态计算的),将范围内各像素的最小深度与x的实际深度比较,从而判断哪些像素是遮挡物，把所有遮挡物的深度记下来取个平均值作为blocker distance。blocker越接近阴影接收物，阴影越硬。
- 用取得的遮挡物深度距离来算在PCF中filtering的范围。
- 进行pcf操作。

#### 33.4 VSSM

- 第一步和第三步明显很慢，需要对一片区域的texel做采样
- PCF：先求出区域的均值和方差，利用概率密度函数，近似算出遮挡的占比
- blocker的平均深度：求出区域均值，求出blocker占比，将未遮挡物的平均深度近似为当前点深度，进而求出blocker的平均深度
- 可以用更高阶的矩来计算概率，这样精度会更高

![img](https://pic4.zhimg.com/80/v2-47adf7e68994b673a9a0d945bb2484af_720w.webp)

![img](https://pic3.zhimg.com/80/v2-39963539630471e639a5948de203b5c6_720w.webp)

#### 33.5 SDF

把shading point和**面光源**相连，所得到的安全角度越小，被遮蔽的可能越高，就可以认为

- **safe angle越小，阴影越黑,越趋近于硬阴影；**

- **safe angle够大就视为不被遮挡没有阴影,也就越趋近于软阴影。**



### 34. 球谐函数

- 一系列定义在球面上的二维函数

![img](https://pic3.zhimg.com/80/v2-ef842c65b84bf82f773ab4b655387a3a_720w.webp)

### 35. PRT（Precomputed Radiance Transfer）

![img](https://pic4.zhimg.com/80/v2-ac89de64010d5e44c6965bde98867b83_720w.webp)

- 我们把rendering equation分为两部分,lighting 和 light transport.
- 对于渲染方程，里面的光照项、可见项、BRDF项均可表面为球面谐波函数函数

![img](https://pic1.zhimg.com/80/v2-2951b777b686f4c78118d7e842763074_720w.webp)

#### 35.1 diffuse物体

- BRDF项为常量，光照项表示为球面谐波函数并将光照项在球面谐波函数下的系数提取出来

![img](https://pic4.zhimg.com/80/v2-063db9e7d2ec8701b04a7cec91f4bfbb_720w.webp)

- 可见项与基函数的积分相当于对可见项进行投影

- 可以理解成对每个光照基函数做一遍光照

![img](https://pic4.zhimg.com/80/v2-1499b4c16aee149846108b79d6cd63b7_720w.webp)

- 缺点：场景不能移动（光源可以旋转）

#### 35.2 gloosy物体

- 对于gloosy物体，brdf不再是常量，需要根据入射方向和出射方向的变化而变化

![img](https://pic1.zhimg.com/80/v2-c11f46219d43de1a0d6fcf6e87ef0994_720w.webp)

- 对于gloosy物体，最后是一个向量×一个矩阵
- 不管进行几次bounce，都是在预计算时计算出light transform即可，实际计算很快
- 如果我们把基函数看为lighting项,那么这就是rendering equation,我们把light transport投影到basis上,相当于用basis这个Lighting照亮物体,每个basis得到一个渲染图,最后我们进行重建从而得出最后的shaing值.
- 缺点：
  - 由于球谐函数的性质，该方法比较适合使用于低频的情况（可用于高频但不合适,如图即使使用了26*26阶的sh仍然得不到比较好的效果）
  - 当改变场景或者材质时需要重新预计算light transport，此外预计算的数据比较大

#### 35.3 小波基函数

- 可以表示全频的信息

- 但是小波也有自己的缺陷：不支持旋转（使用球谐函数进行表示时，由于球谐函数具有**simple rotation**的性质，所以支持光源的旋转）。

### 36. 全局光照

#### 36.1 Reflective shadow map（RSM）—图像空间

- 对于shadowMap上的每个像素点，都作为一个次级光源，且他们都是diffuse的
- 数据存储（类似存储一个沿着光源方向的GBuffer）：

![image-20231205211726274](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231205211726274.png)

- 优点：易于实现
- 缺点：
  - 性能随着直接光源数的增加而降低(因为需要计算更多的shadow map)
  - 对于间接光照，没有做可见性检查
  - 有许多假设：反射物需要是diffuse等
  - 需要在质量和采样率上做一个平衡
- 反射光功率除以面积得到irradiance

#### 36.2 Light Propagation Volumes（LPV）—3D空间

- 将场景划分为若干个3D网格,每个网格叫做Voxel(体素),在计算完直接光照后,将接受到直接光照的表面看作间接光照在场景中传播的起点
- 步骤：
  - 找出接收直接光照的点
  - 把这些点注入(inject)到3D网格中作为间接光照(虚拟光源)的传播起点.
  - 在3D网格中传播radiance
  - 传播完后,渲染场景
- 具体步骤
  - 生成：与RSM一样,首先通过Shadow Map找出接受直接光照的表面或物体，对得到的光源数量可以通过采样一些进行简化从而降低次级光源数量,最后获得一系列虚拟光源
  - 注入：
    - 预先把场景划分为若干个3D网格(体素)
    - 把虚拟光源注入到其对应的格子内
    - 一个格子内可能包含许多不同朝向的虚拟光源,把格子内所有虚拟光源的不同朝向的radiance算出来并sum up从而得到一个往四面八方的radiance
    - 由于是在空间上的分布,也就可以看作是球面函数,自然可以用SH来表示(工业界用两阶SH就可以表示各个方向上的radiance初始值)
  
  ![img](https://pic1.zhimg.com/80/v2-d80895b59bd31396efbf66b649ccc8b4_720w.webp)
  
  - 传播
    - 由于是3D网格,因此可以向六个面进行传播(上下左右前后),由于radiance是沿直线传播的,我们认为radiance是从网格中心往不同方向进行传播的,穿过哪个表面就往哪个方向传播,比如穿过右表面的radiance,就传播到右边的格子里(不考虑斜角,比如右上方向,我们认为是先到右边格子,再到上面格子)
    - 每个格子计算收到的radiance,并用SH表示
    - 迭代四五次之后,场景中各voxel的radiance趋于稳定
  
  ![img](https://pic3.zhimg.com/80/v2-082c251c35d0e94e8cf4da1076542bb2_720w.webp)
  
  - 渲染
    - 对于任意的shading point，找到他所在的网格
    - 获得所在网格中所有方向的Radicae；
    - 渲染
- 缺点：漏光

#### 36.3 Voxel Global illumination（VXGI）—3D空间

![img](https://pic2.zhimg.com/80/v2-f34b0add76d47ae214815628b11dd739_720w.webp)

- 区别1：次级光源从RSM中的Pixel--->VXGI中的Voxel(格子)

- 区别2：光线从传播变为了追踪

- 具体步骤：

  - Light Pass
    - 划分场景为树形网格，打光，对于接收到直接光照的物体，记录其法线和入射方向，这也是跟LPV最大的区别，可以做到glossy物体的渲染（LPV是利用SH记录radiance的分布）

  ![img](https://pic2.zhimg.com/80/v2-54344007c2c6440c856357945222f71d_720w.webp)

  - Camera Pass
    - 对于Glossy的表面，向反射方向追踪出一个锥形(cone)区域基于追踪出的圆锥面的大小，对格子的层级进行查询，就是对于场景中的所有体素都要判断是不是与这个锥形相交，如果相交的话就要把对于这个点的间接光照的贡献算出来(我们存储了体素的光照输入方向和法线方向,因此可以算出其输出的radiance,将cone区域内所有体素的radiance都算出来从而在shading point得到间接光照)，也就是根据传播出的距离远近找对应层级的体素，然后找覆盖的范围。(论文中说查询相当于是mipmap的操作,但是我个人没有看完,等回头有时间将vxgi的论文好好看一遍)
    - 对于diffuse的情况来说,通常考虑成若干圆锥，忽略圆锥Tracing时的重叠和空隙

LPV是把所有的次级光源发出的Radiance传播到了场景中的所有位置，只需要做一次从而让场景每个Voxel都有自己的radiance，但是由于LPV使用的3D网格特性，并且采用了SH进行表示和压缩，因此结果并不准确，而且由于使用了SH因此只能考虑diffuse的,但是速度是很快的。

VXGI把场景的次级光源记录为一个层次结构，对于一个Shading Point，我们要去通过Corn Tracing找到哪些次级光源能够照亮这个点。

#### 36.4 SSAO—屏幕空间

#### 36.5 SSDO—屏幕空间

在SSAO中，认为遮挡的地方不提供间接光照，对于遮挡的地方计算遮挡因子，也就是认为简介光照是从很远的地方来的。

在SSDO中，认为遮挡的地方提供间接光照，也就是假设间接光照是从比较近的物体反射来的。

也是在半球方向生成一些随机采样点，然后根据采样点的可见性，对于被遮挡的位置，取其在Gbuffer上的法线等信息，近似认为其为diffuse物体，计算其radiance信息，从而计算着色。

#### 36.6 SSR—屏幕空间

一种基于屏幕空间的光线反射算法，通过从相机的一根光线到每个个像素点，根据每个像素点上存储的法线信息得到反射光线的方向，再利用这根反射光线去与屏幕空间上的物体求交，求交的方法就是判断射线的深度信息是否从小于变成大于（或者大于变成小于，就是有个跃变），得到交点之后再将交点的着色添加到原先的像素点中。

屏幕空间求交的加速结构的思路：

- 生成深度图的mipmap，mipmap上记录了一定区域内深度的最小值（越小越靠近相机），首先在最底层的深度图上进行查找，法线没有交点则向上一层深度图继续进行查找，直到找到交点

缺点：

- 只会保留屏幕上有的信息，对于屏幕外的信息无法作反射
- 在Diffuse 物体上并不是非常高效

### 37 裁剪技术

- 背面裁剪
- 视锥裁剪

  - **若包围盒的所有顶点都在视锥体的某个面外，那么我们认为这个物体是要被剔除的**（大物体）
  - **即视椎体内的顶点，它的其次裁剪坐标的xyz取值范围应该在(-w~w, -w~w,- w~w)之间**

  ![img](https://pic3.zhimg.com/80/v2-9fa46c79195c8241e2597cd9d13b8662_720w.webp)

  - 确定6个平面
    - 对于远近平面：法线为相机forward方向
    - 其余四个面：三点确定一个平面，相机位置，计算原平面的四个点
  - 确定点在平面外部还是内部
  - Ax+By+Cz+D大于或者小于0
  - Append类型的computerbuffer
- 遮挡剔除

  - 物体覆盖区域的深度值全都小于深度图中对应的该区域的深度值，则物体需要被剔除（逐对象剔除）
  - 通过mipmap的方法快速得到深度图上一个区域内的最小值
  - 计算物体的最大深度，通过比较物体的最大深度是否小于深度图上对应区域的最小深度，得到是否需要剔除该物体
  - 通过物体占据的区域（NDC空间下） X 0.5 X 原始深度图尺寸得到在原始深度图下应该占据像素范围，然后取log得到在哪一级的mipmap，采样深度图上采样点周围四个像素得到占据区域的最小深度

- 入口裁剪

### 38. 变换顺序

- 先缩放、再旋转最后平移
- 缩放不能再旋转之后，缩放和旋转不能在平移之后

### 39. 欧拉角、矩阵、四元数表示旋转的区别和优缺点（非常重要

#### 39.1 欧拉角

- 定义了绕着三个坐标轴的旋转角，来确定刚体的旋转位置的方式，包括俯仰角pitch，偏航角yaw和滚动角roll；
- 万向节死锁

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1689217649993-f92d3af5-8f60-43c2-81e3-cadd5fabe5ad.png?x-oss-process=image%2Fresize%2Cw_750%2Climit_0)

#### 39.2 四元数

- 优点：
  - 解决万向节死锁（Gimbal Lock）问题
  - 仅需存储4个浮点数，相比矩阵更加轻量
  - 四元数无论是求逆、串联等操作，相比矩阵更加高效

### 40. 如何渲染同时存在不透明物体和透明物体的场景

- 一般步骤：

  - 首先开启深度写入，在第一个Pass渲染所有的不透明物体

  - 从后往前渲染半透明物体，开启深度测试和透明度混合，但是关闭深度写入

- 存在的问题：
  - 物体可能一部分在另一物体前面，一部分在后面，这样子就很难做到真正的从后往前
  - 透明物体内部各个三角形面片的前后关系混乱
- 优化：
  - 对于每一个半透明物体都执行两个Pass，第一个Pass记录深度信息，第二个Pass真正进行透明度混合
  - 开启透明度混合，第一个Pass只渲染背面，第二个Pass只渲染正面

### 41. 实时光线追踪

1SPP：至少要有四条光线才能构成一个最基本的光路:

- primary hitpoint(从camera出发打出一根光线打到的交点)
- shadow ray(primary hitpoint 和光源之间连接进行light sampling并判断是否有遮挡)
- secondary ray(在Hitpoint根据材质采样出一个方向打出一根光线,他会打到一个物上从而得到secondary hitpoint)
- secondary shadow ray(从secondary hitpoint与光源连接判断是否会被光源看到)

时间上的降噪：

- 如果在进行rasterization(primary ray)时得到了世界坐标信息的图存储在G-buffer中则直接得到世界坐标
- 如果没有其信息,则在当前帧的像素通过逆视口变换和逆MVP变换得到世界坐标
- 已知motion矩阵,将世界坐标逆motion得到上一帧的世界坐标
- 将上一帧的世界坐标进行正MVP变换和视口变换得到当前帧中的像素在上一帧中的位置
- 将两个值线性blending起来从而得到当前帧最后的结果

问题：

- 突然切换场景或者光源会因为上一帧没有对应的信息从而出现错误的显示
- 对于倒退的场景无法在上一帧找到对应的像素.
- 出现残影/拖尾现象
- 场景不动的情况下 motion vector为0,如果shading改变会出现错误的显示
- 地板上反射出场景的情况来说,由于地板是不动的,其上面的每一个像素点的motion vector为0,当我们移动物体时,其地板需要一定的时间适应，之后再在地板上反射出当今场景中的物体，也就是反射滞后

解决方案：

- clamping：将上一帧的像素颜色拉近到这一帧的结果再进行混合，对于当前这一帧的像素点，取周围一定区域内的像素，计算均值和方差，然后判断上一帧的结果是否在该范围内
- Detection：判断计算出来的像素位置上对应的物体与这一帧是否为同一个物体，如果不是就不使用混合
- 但是这种解决方案会带来噪声

滤波：

滤波所做的概括起来就是做了一个模糊的操作，把一些噪声消除，也就是将一个比较noisy的图，降噪从而得到一个干净的图。保留低频信息，将高频噪声去除。

- 高斯滤波核
- 双边滤波：通过高斯我们得到了一个整体都被模糊的结果，但是我们想让边界仍然锐利，因此除了高斯我们需要其他的方法来帮助我们保留下边界的这些高频信息。核心思想就是对于像素差距较大的点，可以认为在边界的两边，那么它贡献到中心像素的权值就应该较小

![img](https://pic2.zhimg.com/80/v2-debc6ce776c4f840e90ee04424a3536d_720w.webp)

- 联合双边滤波：单单使用像素的颜色差异判断是否为边界过于草率，很有可能是由于噪声的差异带来的两个点的颜色差异，联合双边滤波使用了更多参数来计算权值（法线、深度、位置和物体ID），注意这里不是只能使用高斯函数，一切关于距离衰减的函数都能使用。

![img](https://pic2.zhimg.com/80/v2-15ddb9469f8d5ba33f7d347b6e8ae575_720w.webp)

- 注意对于大的高斯滤波，会有性能上的损失，即需要做N×N的遍历，但是这种遍历可以转变成N+N的遍历，理论上只适用于高斯滤波，但是用在双边滤波和联合双边滤波也没多大关系
- 用一个逐步增大的filter，比如先用一个小的filter，然后用中号的filter，最后是大号的filter，通过多趟的filter得到N*N的filter得到的结果。这样做的好处在于，本来是64×64的卷积核，可以拆分成5个5×5的卷积核

![img](https://pic4.zhimg.com/80/v2-217590517d53d4b07a5a3f6d647fcf8b_720w.webp)

- 采样是对频谱的搬移，采样更秘，频谱搬移的距离更大，采样更稀疏，频谱搬移的距离更小，更容易造成频谱的重叠
- 对于PCSS和SSR，也可以采用滤波的方式让其变得干净

**对于一些超级亮的点**：平常我们在是用蒙特卡洛方法渲染一张图时,得到的结果会出现一些点过亮或者过暗,这些过亮或者过暗的点如果经过使用filter这种降噪的方法去处理的话不好处理,以7*7的filter为例,如果有一个点过亮,在经过这个7*7的filter处理过后,会影响一块区域,使得它这一块区域变亮.

那么我们是否可以**在filter之前处理掉**这些过亮或者过暗的点?而且我们如何去定义这个outlier也就是这个边界呢?

![img](https://pic4.zhimg.com/80/v2-24e22056e97c5e47c5c6728480fe5e27_720w.webp)

- 计算区域内的均值和方差，对于超过一定范围的像素点，则clamp到有效范围内。
- 对于有光源的场景，为了避免将光源滤波掉，可以先渲染没有光源的一张图，最后再将光源加上

### 42. SVGF

- 深度

![img](https://pic4.zhimg.com/80/v2-05794a66385b4b3daaa4d039c8b1a8f7_720w.webp)

**(垂直于平面法线上的变化 \* 距离 = 实际深度变化量)**

**如果实际深度变化量也很大,从而告诉我们这个平面是侧向我们的,在这种情况下来看公式,虽然分子深度差异大,但是分母中的梯度也大,二者一除,值就没那么大了,因此EXP()得到的值就大了.**

**总结来说,通常情况下不会简单的用二者之间的深度差异来判断贡献值,而是在他们所在的面的法线方向上投影出来的深度差异来判断,或者说是在它们所在平面上的切平面上的深度差异.**

- 法线

![img](https://pic2.zhimg.com/80/v2-304f3e393f50f48d4be291b024d66a2d_720w.webp)

- 颜色差异

![img](https://pic1.zhimg.com/80/v2-f2e51848f05cf570a367cb07746aaa84_720w.webp)

**看A，B两点间的颜色差异，并且思考filter的中心点的variance，当variance比较大时，我们不应该去过多的相信两点间的颜色差异。这就是为什么会去除以一个标准差。**

### 43. Tile Shading

Tiled shading是建立在Deferred Shading的基础之上，将屏幕分成若干个小块，比如一个小块是32 * 32，然后对每个小块单独的做shading。

![img](https://pic2.zhimg.com/80/v2-4ec659acb7dac4feaa21494e98be99e9_720w.webp)

- 节省每个小块要考虑的light数量，每个切出来的小块代表场景中3D的区域，并不是所有的光源都会跟这片区域相交。
- 我们在做light sampling时知道光照强度会随着距离的平方衰减，因此面光源或点光源的覆盖范围是很小的，我们根据其随距离平方的减少找出最小值，也就是设定一个范围，光源的覆盖范围看做一个球形。因此我们在渲染时，只需要找会影响到区域的光源即可，不需要考虑所有的光源。
- 如图，数字代表区域内会影响到它的光源数量。
- 复杂度：O(#vis.frag. * **#light)->O(#vis.frag. \***avg light)
- 但在此之后，又有人对其进行了一个复杂的优化。

### 44. Clustered Shading

![img](https://pic2.zhimg.com/80/v2-5783600b2bceeecf3a41d582e5c535dd_720w.webp)

- 如果只分成若干个小块区域的话，区域内的深度可能会十分大
- 因此光源可能会对这个小块区域有贡献，但不一定会对根据深度细分后的网格有贡献。所以再划分过后我们可以发现每个网格内的光源数量更少了。
- **Complexity:O(#vis.frag. \* avg #light per tile)->O(#vis. frag. \* avg #light per cluster)**

### 45. Cascaded ShadowMap

![img](https://pic1.zhimg.com/80/v2-6d93209bf37869377030973984f85fc4_720w.webp)

- Unity 和大多数游戏引擎都会将阴影投射器渲染成纹理，然后对其进行采样以创建阴影。这些阴影贴图的分辨率是固定的。如果阴影贴图必须覆盖很大的区域，那么单个像素也会变得很大，从而造成块状阴影。
  通过减小最大阴影距离，我们可以减少阴影贴图必须覆盖的区域，从而提高阴影质量，但代价是会丢失远处的阴影。
  阴影级联在此基础上更进一步，根据距离的远近使用多个阴影贴图，从而使附近的阴影比远处的阴影具有更高的分辨率。两种渲染管道都支持多达四个级联。

- 从图中可以看到会有重叠区域内，因为在突然切换层级时会有一个突变的artifact,为了有一个平滑的过度，在这个区域内我们通过距离，也就是近处的以蓝色区域的shadow map为主将二者blend起来，从而产生平滑的过度。

### 46. 渲染架构

#### 46.1 IMR

- 每一次渲染的提交（可以是一个也可以是一批对象），都要读取当前的`Color/Depth Buffer`，然后再写回。需要大量的带宽，而对移动端的GPU来说，大量的带宽，带来的是高功耗，因此移动端采用下面TBR的方案

#### 46.2 TBR

- Tile-Based是指渲染不再以当前Frame Buffer尺寸为单位，而是分成一个个Tile。渲染前有个Tiling Pass，来判断三角形Rasterization (光栅化)到哪个Tile中。TBR 将 IMR 中对`Color/Depth Buffer`进行的读写操作，改为对GPU片上高速内存的读写操作，大大提升速度。

#### 46.3 TBDR

- TBDR (Tile-Based Deferred Rendering)在TBR (Tile-Based Rendering)的基础上，通过硬件层面的特性HSR (隐藏面消除)解决了Overdraw问题 。说它是真正的TBDR，是因为延迟不仅体现在TBDR是在处理完所有的VS（几何处理）之后，才做的Rasterization (光栅化)，而且在Rasterization (光栅化)后，通过HSR (隐藏面消除)避免了不必要的Fragment Shader (片元着色器)计算，实现了从光栅化到片元着色器的延迟。



### 47. 立方体贴图

- 需要把Z值设置为1，并且移除相机移动

```glsl
localPos = aPos;

mat4 rotView = mat4(mat3(view)); // remove translation from the view matrix
vec4 clipPos = projection * rotView * vec4(localPos, 1.0);

gl_Position = clipPos.xyww;
```



## unity

### 1. 光源渲染规则

- **最亮的几个光源会被实现为像素光照**
- **然后最多4个点光源会被实现为顶点光照**
- **剩下的光源会被实现为效率较高的球面调谐光照（Spherical Hamanic），这是一种模拟光照**

- 在前向渲染中，有两个Pass，ForwardBase用来计算主方向灯、逐像素的平行光以及所有逐顶点个SH光源，ForwardAdd逐像素光源数量范围内的灯光计算，都会调用一次这个Pass来进行计算，计算后的结果再通过Blend One One的混合模式叠加起来。

### 2. Tag

- RenderQueue：决定物体渲染顺序，2500是透明和不透明的分界点

![image-20231130152445270](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231130152445270.png)

- lightMode：用于在渲染管线中指定着色器要执行的Pass

  - SRPDefaultUnlit
  - ShadowCaster


### 3. 常用的头文件

- unityCG.cginc：各种变换矩阵
- Lighting.cginc和AutoLight.cginc：各种光照模型、内置变量

### 4. unity脚本的生命周期

#### 4.1 reset

- 当脚本第一次绑定到物体或者按下reset按钮时触发

#### 4.2 awake

- 脚本实例在游戏运行被载入的时候运行，一般为初始化游戏变量和游戏状态，注意无论脚本是否被激活，Awake都会被执行

#### 4.3 onEnable

- 仅在游戏对象是可激活状态时调用，**取消激活后再次激活也会响应**。常用于对象池。
- 在创建 MonoBehaviour 实例时（例如加载关卡或实例化具有脚本组件的游戏对象时）会执行此调用。
- 此时场景已加载完，GameObject已实例化。

#### 4.4 Start

- 仅当启用脚本实例后(Awake 和 OnEnable执行后)，才会在第一次帧(update)更新之前调用 Start。
- Awake是在项目初始化的时候调用，Start在项目初始化之后调用；若一些状态放在Start中初始化，会造成空引用问题。建议尽量在Awake中初始化。比如需要引用单例对象
- 如果对象不处于激活状态，start不会运行，awake会运行

#### 4.5 FixedUpdate

- 每一帧会执行的调用（固定间隔），所有的物理行为的每帧更新的逻辑都应在放在这里面，比如刚体的运算，或者施加一个力，如果直接放在update函数中可能会出现一顿一顿的情况
- FixedUpdate的帧率是固定的，由FixedTimestepd的值决定，路径：Edit->ProjectSetting->Time->FixedTimestep。但每一帧的时间间隔不固定，如果每帧都有大量的运算，为了避免运算超时影响主帧（Update），逻辑运算受临界值MaximumAllowedTimestep控制，超出时间就会退出运算。
- 而Update帧率不固定，会受到时间缩放的影响，会出现卡顿的情况。
- 调用FixedUpdate的频度常常超过Update。

#### 4.6 OnTrigger、OnCollision、OnMouse

- 处理触发器行为、处理碰撞行为、处理鼠标点击行为

#### 4.7 Update

- 每一帧进行调用，是实现游戏逻辑的主要方法。

#### 4.8 LateUpdate

- 在Update方法执行之后执行，一般用于摄像机的跟随

#### 4.9 OnDisable

- 与OnEnable相对应

#### 4.10 OnDestory

- 与Awake对应

## 游戏引擎

### 1. 对象池

#### 1.1 对象池解决什么问题

- 对象的**实例化可能是一个比较繁重的工作**, 比如预制的实例化, 需要将在背后做很多事情, 如加载其依赖的资源, 实例化这些资源, 给资源对象赋值, 给预制对象赋值, 最终得到预制的实例化对象. 针对同一个预制, 如果需要多次使用和销毁其实例化对象, 会造成资源浪费和卡顿, 我们可以在不使用的时候将其实例化对象保存下来而不是直接销毁, 在下次使用时**直接给予缓存的对象而不需要进行实例化**, 这样可以充分利用资源, 也可以加速进程.
- **简单的说对象池就是将不需要使用的多个对象存下来, 下次需要使用时直接给予而不再进行实例化的技术.**
- 在我们游戏开发中最常见的对象池技术的实例就是子弹的使用.
- 想象一下, 如果不使用对象池, 我们就会频繁的创建和销毁对象, 这对性能是很大的影响.
- 对象池是一个典型的**空间换时间**的技术, 为了玩家流畅的体验, 我们一般会在进入场景前预加载和预创建好一定数量的对象存放在对象池中, 然后在游戏过程中直接拿来使用即可.
- 我们有一把枪，开枪的时候射出子弹。每个子弹即一个对象，正常情况，我们的处理方式可能会是，每开一枪，就GameObject.Instantiate()一个新的子弹，当子弹到达极限距离的时候再GameObject.Destroy()销毁它。假设有射出1000发子弹，我们就会执行1000次这样的操作，然而在Unity中Instantiate和Destroy操作，不仅影响性能还容易产生内存碎片，总之就是要尽量少做这种操作。这个时候就有对象池这个概念。

#### 1.2 对象池实现

- 所谓对象池，就是针对需要经常生成消失的对象。我们**在对象需要消失的时候不是Destroy而是SetActive(false)，然后放入池子中(Queue)**，**当需要再次显示一个新的对象的时候，先去池子中看有没有隐藏的对象，有就取出SetActive(true)，若池子里没有可用的则再**[**Instantiate**](https://so.csdn.net/so/search?q=Instantiate&spm=1001.2101.3001.7020)**。**



## 项目

### 1. 动态顶点数组+动态顶点布局+动态常量结构体构造系统

- 作用是存储顶点数据，实现一个类似C++ vector中emplace_back函数的功能（利用可变参数模板及其展开+右值传递），可以插入更多的顶点，还包括重写索引运算符这样可以得到一个特定的顶点等。这里面还包括了重定义类型如Position3D、Position2D、Tex2D、Normal等等，然后建立了一个映射表，可以从自定义类型转换为系统变量。
- 在顶点数组中维护一个动态顶点布局系统，用来描述一组顶点属性的分布，主要包括了类型和个数（比如position是3个float，纹理坐标是2个float等），以及各个属性在数据中的偏移量，主要是为了适配OpenGL和DX11中描述顶点布局的函数。
- 动态 常量结构体构造系统，shader中有一片常量缓冲区用来传入shader计算需要的常量，如openGL中的uniform和DX11的cbuffer，他们都存在内存对齐的问题需要解决，同时，不同模型加载进来含有的贴图数量不同，如果没有这样一个系统来动态的确定常量结构体各个变量，就会存在很多ifelse的判断，代码重复度很高，比如有没有法线贴图、高光贴图等。实现的方式与上面的动态数组的方式类似，也是先构建一个layout系统描述这个常量缓冲区结构体含有什么变量类型，然后再构造一块CPU内存存放这些变量，这里就可以实现自动对齐（16个字节）的功能。

- DX11中是16个字节的对齐，OpenGL是基于std140准则

### 1.2 renderGraph

- 大的Graph系统将各个pass集成在一起
- pass内包含了sink和source，即输入资源和输出资源，还有一些特定操作，如关闭深度写入等等。

## C++

### 1. C++风格的类型转换

#### 1.1 C风格转化的缺点

- 没有从形式上体现转换功能和风险的不同。
  - 将 int 强制转换成 double 是没有风险的，而将常量指针转换成非常量指针，将基类指针转换成派生类指针都是高风险的，而且后两者带来的风险不同（即可能引发不同种类的错误），C语言的强制类型转换形式对这些不同并不加以区分。
- 不检查安全性
- 难以在程序中寻找到底什么地方进行了强制类型转换

#### 1.2 各种风格转换

- **reinterpret_cast**：对指针的类转或者引用类型做类型转换，从位模式上进行重新解释，不做安全检查
- **const_cast**：仅用于进行去除 const 属性的转换，const_cast只能用于指针或引用，**并且只能改变对象的底层const（顶层const，本身是const，底层const，指向对象const）**
- **dynamic_cast**：用 reinterpret_cast 可以将多态基类（包含虚函数的基类）的指针强制转换为派生类的指针，但是这种转换不检查安全性，即不检查转换后的指针是否确实指向一个派生类对象。dynamic_cast专门用于将多态基类的指针或引用强制转换为派生类的指针或引用，而且能够检查转换的安全性。对于不安全的指针转换，转换结果返回 NULL 指针。dynamic_cast父类一定要有虚函数，否则编译不通过

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688568587590-0fe7ba06-9ad8-4903-95cc-85a8fe0c6881.png)

- **static_cast**：用于进行比较“自然”和低风险的转换，如整型和浮点型、字符型之间的互相转换。另外，如果对象所属的类重载了强制类型转换运算符 T（如 T 是 int、int* 或其他类型名），则 static_cast 也能用来进行对象到 T 类型的转换。static_cast 不能用于在不同类型的指针之间互相转换，也不能用于整型和指针之间的互相转换，当然也不能用于不同类型的引用之间的转换。因为这些属于风险比较高的转换。
- **static_cast和dynamic_cast的异同点？**
  - 二者都会做类型安全检查，只是static_cast在编译期进行类型检查，dynamic_cast在运行期进行类型检查。后者需要父类具备虚函数，而前者不需要

### 2. 多态和虚函数

- 什么是多态？C++多态是如何实现的？

  - 所谓多态，就是同一个函数名具有多种状态，或者说一个接口具有不同的行为；C++的多态分为编译时多态和运行时多态，编译时多态也称为为静态联编，通过重载和模板来实现，运行时多态称为动态联编，通过继承和虚函数来实现

- **虚函数的实现机制是什么**

- - 虚函数是通过虚函数表来实现的，虚函数表包含了一个类(所有)的虚函数的地址，在有虚函数的类对象中，它内存空间的头部会有一个虚函数表指针(虚表指针)，用来管理虚函数表。当子类对象对父类虚函数进行重写的时候，虚函数表的相应虚函数地址会发生改变，改写成这个虚函数的地址，当我们用一个父类的指针来操作子类对象的时候，它可以指明实际所调用的函数。
  - **如果子类中不存在虚函数，那么子类的虚指针将直接指向父类的虚函数表，如果子类中有虚函数，则会产生自己的虚函数表；如果没有将父类中的虚函数全部重载，那么没有被重载的虚函数指针将会指向父类虚函数的地址**。

- **虚函数调用是在编译时确定还是运行时确定的？如何确定调用哪个函数？（****虚函数的动态绑定）**

- - 关键在于指针指向的类是谁，这决定了去查哪个类的虚函数表
  - 只有通过指针或者引用的方式调用虚函数是运行时确定，通过值调用的虚函数是编译期就可以确定的

- **虚函数是存在类中还是类对象中（即是否共享虚表）？**

- - 存在类中，不同的类对象共享一张虚函数表(为了节省内存空间)。

- **在(基类的)构造函数和析构函数中调用虚函数会怎么样**？

- - 从语法上讲，调用没有问题，但是从效果上看，往往不能达到需要的目的（不能实现多态）；因为调用构造函数的时候，是先进行父类成分的构造，再进行子类的构造。在父类构造期间，**子类的特有成分还没有被初始化，此时下降到调用子类的虚函数，使用这些尚未初始化的数据一定会出错**；同理，调用析构函数的时候，先对子类的成分进行析构，**当进入父类的析构函数的时候，子类的特有成分已经销毁，此时是无法再调用虚函数实现多态的**。

- 

### 3. 内存模型，继承问题

- **c++中类对象的内存模型(布局)是怎么样的？**

- **钻石(菱形)继承存在什么问题，如何解决**？

存在二义性问题，两个父类会对公共基类的数据和方法产生一份拷贝，因此对于子类来说读写一个公共基类的数据或调用一个方法时，不知道是哪一个父类的数据和方法，也会导致编译错误。可以采用虚继承的方法解决这个问题(父类继承公共基类时用virtual修饰)，这样就只会创造一份公共基类的实例，不会造成二义性





### 4. 内存管理（内存分配、内存对齐）

- **C++是如何做内存管理的（有哪些内存区域）?**
  - 堆区
  - 栈区
  - 全局/静态存储区
  - 常量存储区
  - 自由存储区
  - 特别注意：
    - 堆是C语言和操作系统的术语、是操作系统维护的一块内存，自由存储区是C++中通过new与delete动态分配和释放对象的抽象概念。堆与自由存储区不等价
- **堆和栈的内存有什么区别？**
  - 管理方式
  - 空间大小
  - 碎片问题
  - 分配方式
  - 分配效率
  - 地址增长方向
- **C++和C分别使用什么函数来做内存的分配和释放？有什么区别，能否混用？**
  - 返回指针类型
  - 调用构造和析构函数
- **什么是内存对齐(字节对齐)，为什么要做内存对齐，如何对齐？**
  - 原因
  - 内容：内存对齐指的是C++结构体中的数据成员，其内存地址是否为其对齐字节大小的倍数
  - 对齐原则：
    - 结构体变量的首地址能够被其最宽基本类型成员的对齐值所整除
    - 结构体总体大小能够被最宽成员大小整除；如果不满足这些条件，编译器就会进行一个填充(padding)
    - 结构体内每一个成员的相对于起始地址的偏移量能够被该变量的大小整除
  - alignas：返回结构体的对齐方式；alignof：指定结构体的对齐方式（若`alignas`小于自然对齐的最小单位）



### 5. 智能指针

- **C++中的智能指针有哪些，各自有什么作用**

  - 智能指针分为不带引用计数的scoped_ptr和unique_ptr，带引用计数的shared_ptr和weak_ptr

  - unique_ptr删除了拷贝构造函数和赋值函数，因此不支持普通的拷贝或赋值操作。但引入了移动构造函数和移动赋值运算符。所以它们保证了有唯一的智能指针持有此资源。unique_ptr还提供了reset重置资源，swap交换资源等函数，也经常会使用到

  - shared_ptr称为强智能指针，**它的资源引用计数器在内存的heap堆上**（这保证了，每个智能指针的引用计数变量会动态的变化）。通常用于管理对象的**生命周期**。只要有一个指向对象的shared_ptr存在，该对象就不会被析构

  - weak_ptr被称为弱智能指针，其对资源的引用**不会引起资源的引用计数的变化**，通常作为观察者，用于判断资源是否存在，并根据不同情况做出相应的操作。比如使用weak_ptr对资源进行弱引用，当调用weak_ptr的lock()方法时，若返回nullptr，则说明资源已经不存在，放弃对资源继续操作。否则，将返回一个shared_ptr对象，可以继续操作资源。另外，一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放。即使有weak_ptr指向对象，对象也还是会被释放

- **如何避免循环引用**
  - 解决办法，这也是强弱智能指针的一个重要应用规则：**定义对象时，用强智能指针shared_ptr**，在其它地方引用对象时，使用弱智能指针**weak_ptr**
- **shared_ptr的实现原理是什么？构造函数、拷贝构造函数和赋值运算符怎么写？shared_ptr是不是线程安全的**
  - shared_ptr是通过引用计数机制实现的，引用计数存储着有几个shared_ptr指向相同的对象，当引用计数下降至0时就会自动销毁这个对象
  - 具体实现：
    - 构造函数：将指针指向该对象，引用计数置为1
    - 拷贝构造函数：将指针指向该对象，引用计数++
    - 赋值运算符：=号左边的shared_ptr的引用计数-1，右边的shared_ptr的引用计数+1，如果左边的引用技术降为0，还要销毁shared_ptr指向对象，释放内存空间
  - shared_ptr的引用计数本身是安全且无锁的，但是它指向的对象的读写则不是，因此可以说shared_ptr不是线程安全的
- **weak_ptr是为了解决shared_ptr的循环引用问题，那为什么不用raw ptr来解决这个问题？**
  - 一个weak_ptr绑定到shared_ptr之后不会增加引用计数，一旦最后一个指向对象的shared_ptr被销毁，对象就会被释放，即使weak_ptr指向对象，也还是会释放；但是raw指针，当对象销毁之后会变成悬浮指针，容易导致不可预估的错误

### 6. 各种关键字

- **const的作用？指针常量和常量指针？const修饰的函数能否重载？**

  - const修饰符用来定义常量，具有不可变性。在类中，被const修饰的成员函数，不能修改类中的数据成员
  - const修饰的函数可以重载。const成员函数既不能改变类内的数据成员，也无法调用非const的成员函数；const类对象只能调用const成员函数，非const对象无论是否是const成员函数都能调用，但是如果有重载的非const函数，非const对象会优先调用重载后的非const函数

- **static的作用？static变量什么时候初始化？**

  - static 作用：控制变量的存储方式和可见性
  - 作用一：修饰局部变量
    - ⼀般情况下，对于局部变量在程序中是存放在栈区的，并且局部的生命周期在包含语句块执行结束时便结束了。但是如果用static关键字修饰的话，该变量便会存放在静态数据区，其生命周期会⼀直延续到整个程序执行结束。但是要注意的是，虽然用static对局部变量进行修饰之后，其生命周期以及存储空间发生了变化，但其作用域并没有改变，作用域还是限制在其语句块
  - 作用二：修饰全局变量
    - 对于一个全局变量，它既可以在本文件中被访问到，也可以在同一个工程中其它源文件被 访问(添加 extern进行声明即可)。用static对全局变量进行修饰改变了其作用域范围，由原来的整个工程可见变成 了本文件可见
  - 作用三：修饰函数
    - 用static修饰函数，情况和修饰全局变量类似，也是改变了函数的作用域
  - 作用四：修饰类
    - 如果 C++ 中对类中的某个函数用static修饰，则表示该函数属于⼀个类而不是属于此类的任何特定对象；如果对类中的某个变量进行static修饰，则表示该变量以及所有的对象所有，存储空间中只存在一个副本，可以通过；类和对象去调用。（补充：静态非常量数据成员，其只能在类外定义和初始化，在类内仅是声明而已。）
  - 全局变量、文件域的静态变量和类的静态成员变量在main执行之前的静态初始化过程中分配内存并初始化；局部静态变量在第一次使用时分配内存并初始化

- **extern的作用**

  ![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688618498169-a03f9937-5fc0-4890-a744-21f417206eb2.png)

- **explicit的作用？**
- **constexpr的作用？**
  - 这个关键字明确的告诉编译器应该去验证(函数或变量)在编译期是否就应该是一个常数（这样编译器就可以大胆进行优化）

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688620266040-8f3481e8-efbd-469f-9280-9bb0c7ef772e.png)

- **volatile的作用？**
  - volatile关键词影响编译器编译的结果，用volatile声明的变量表示该变量随时可能发生变化，与该变量有关的运算，不要进行编译优化，以免出错

![image-20231207195552197](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231207195552197.png)

![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688620381052-a54f7c84-0963-4084-89aa-8022c9733fd7.png)

- **mutable的作用？**
  - 使类中被声明为const的函数可以修改类中的非静态成员

- **auto和deltype的作用和区别？**
  - 用于实现类型自动推导，让编译器来操心变量的类型；auto不能用于函数传参和推导数组类型，但deltype可以解决这个问题

![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688620816020-676c4638-44a7-485a-9937-c2dc3f99cf50.png)

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688620861047-8efaeb6c-5f2d-4e90-b96d-6e7becedc859.png?x-oss-process=image%2Fresize%2Cw_500%2Climit_0)

### 7. 左值右值，构造函数、移动语义（重要）

- **什么是左值和右值，什么是右值引用，为什么要引入右值引用**

  - 左值就是具有**可寻址**的存储单元，并且能由用户改变其值的量，比如常见的变量：一个int，float，class等。左值具有持久的状态，直到离开作用域才销毁，**请注意，字符串字面量“hello”是左值！！！**

  - 右值表示**即将销毁的临时对象，具有短暂的状态**，比如字面值常量'h'，返回非引用类型的表达式int func()等，都会生成右值；

  - ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688627199688-92fb92c5-51a1-46c8-9733-1bca04e2a3e1.png?x-oss-process=image%2Fresize%2Cw_425%2Climit_0)

  - ![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688627987621-203789f2-0df8-4ba9-a9d3-2025ddc76863.png)

  - 右值引用就是必须绑定到右值的引用，可以通过&&（两个取地址符）来获得右值引用；右值引用只能绑定到即将销毁的对象，因此可以自由地移动其资源

  - 右值引用是为了支持移动操作而引出的一个概念，它只能绑定到一个将要销毁的对象，使用右值引用的移动操作可以避免无谓的拷贝，提高性能。使用std::move()函数可以将一个左值转换为右值引用。（可以通过两个很长的字符串的直接赋值和移动赋值来测试一下性能的差距)。
  - ![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688628463625-ca67a52d-9b9c-4072-aac9-d553a3bae023.png)

  - ![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688628494887-94757a5f-2286-4d71-9ce6-0e9e925b2f9a.png?x-oss-process=image%2Fresize%2Cw_500%2Climit_0)

  - ![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688628603196-bfaf3a9b-71a7-47aa-a836-949a65d2ab22.png)

- **为什么要自己定义拷贝构造函数？什么是深拷贝和浅拷贝？**
  - 拷贝构造函数的作用就是定义了当我们用同类型的另外一个对象初始化本对象的时候做了什么，在某些情况下，如果我们不自己定义拷贝构造函数，使用默认的拷贝构造函数，就会出错。比如一个类里面有一个指针，如果使用默认的拷贝构造函数，会将指针拷贝过去，即两个指针指向同个对象，那么其中一个类对象析构之后，这个指针也会被delete掉，那么另一个类里面的指针就会变成野指针（悬浮指针）
  - 这也正是深拷贝和浅拷贝的区别，浅拷贝只是简单直接地复制指向某个对象的指针，而不复制对象本身，新旧对象还是共享同一块内存。 但深拷贝会另外创造一个一模一样的对象，新对象跟原对象不共享内存，修改新对象不会改到原对象
- **什么是移动构造函数，和拷贝构造函数的区别？**
  - 移动构造函数需要传递的参数是一个右值引用，移动构造函数不分配新内存，而是接管传递而来对象的内存，并在移动之后把源对象销毁；移动拷贝构造函数需要传递一个左值引用，可能会造成重新分配内存，性能更低

### 8. 内联函数与宏

- **内联函数有什么作用？存不存在什么缺点**？

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688631172101-e331fce4-0aa2-499d-9ce2-8afd4175f1aa.png?x-oss-process=image%2Fresize%2Cw_549%2Climit_0)

- **内联函数和宏有什么区别，有了宏为什么还需要内联函数?**
  - define宏命令是在预处理阶段对命令进行替换，inline是在编译阶段在函数调用点处直接展开函数，节省了函数调用的开销
  - define的话是不会对参数的类型进行检查的，因此会出现类型安全的问题，比如定义一个max命令，但是传递的时候可能会传递一个整数和一个字符串，就会出错，但是内联函数在编译阶段会进行类型检查
  - 使用宏的时候可能要添加很多括号，比较容易出错

### 9. Struct和Class的区别

- 因此它们最大的区别其实是struct默认以public的形式公开内部，而Class是以private的形式，相当于一个是值类型，一个是引用

### 10. 对类对象使用delete this的后果

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1692938827071-326ce23c-f932-4e21-bc04-adeffca73cf7.png)

### 11. C++11的新特性

- auto关键字，可以自动推断出变量的类型

- nullptr来代替NULL，可以避免重载时出现的问题（一个是int，一个是void*）;
  - 关键原因：C++ 不允许直接将 void * 隐式转换到其他类型

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688635318341-e3d3db6e-95a5-4134-8af9-edd0133f9a48.png)

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688635335273-fdb8b532-7931-4583-9f7f-0474ba09bf72.png)

- 智能指针
- 右值引用，基于右值引用可以实现移动语义和完美转发，消除两个对象交互时不必要的对象拷贝，节省运算存储资源，提高效率
- lambda表达式，可以理解为一个匿名的内联函数。

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688698436094-4921cf30-d9dd-4ba6-aac3-448363a2028a.png?x-oss-process=image%2Fresize%2Cw_500%2Climit_0)

![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688698599717-2d2bb3f8-61b7-4125-a312-058952b7a9cc.png)

![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688698611809-3f008afc-aa15-40ad-9cb9-7f67ba18afce.png)

## STL、数据结构、算法

### 1. STL各种容器的底层实现？

####  1.1 vector

底层是一块具有连续内存的数组，vector的核心在于其长度自动可变。vector的数据结构主要由三个迭代器(指针)来完成：指向首元素的start，指向尾元素的finish和指向内存末端的end_of_storage。vector的扩容机制是：当目前可用的空间不足时，分配目前空间的两倍或者目前空间加上所需的新空间大小

#### 1.2 list

底层是一个循环双向链表，链表结点和链表分开独立定义的，结点包含pre、next指针和data数据。

#### 1.3 deque

双向队列，由分段连续空间构成，每段连续空间是一个缓冲区，由一个中控器来控制。它必须维护一个map指针（中控器指针），还要维护start和finish两个迭代器，指向第一个缓冲区，和最后一个缓冲区。deque可以在前端或后端进行扩容，这些指针和迭代器用来控制分段缓冲区之间的跳转。

#### 1.4 stack和queue

栈和队列。它们都是由deque作为底层容器实现的，他们是一种容器配接器，修改了deque的接口，具有自己独特的性质（此二者也可以用list作为底层实现）；stack是deque封住了头端的开口，先进后出，queue是deque封住了尾端的开口，先进先出。

#### 1.5 priority_queue

优先队列。是由以vector作为底层容器，以heap作为处理规则，heap的本质是一个完全二叉树。

#### 1.6 set和map

底层都是由红黑树实现的。红黑树是一种二叉搜索树，但是它多了一个颜色的属性。红黑树的性质如下：

- 每个结点非红即黑
- 根节点是黑的
- 如果一个结点是红色的，那么它的子节点就是黑色的
- 任一结点到树尾（NULL）的路径上含有的黑色结点个数必须相同。通过以上定义的限制，红黑树确保没有一条路径会比其他路径多出两倍以上；因此，红黑树是一种弱平衡二叉树，相对于严格要求平衡的平衡二叉树来说，它的旋转次数少，所以对于插入、删除操作较多的情况下，通常使用红黑树

平衡二叉树(AVL)和红黑树的区别：AVL 树是高度平衡的，频繁的插入和删除，会引起频繁的rebalance（旋转操作），导致效率下降；红黑树不是高度平衡的，算是一种折中，插入最多两次旋转，删除最多三次旋转

- 

### 2. STL各种容器的查找、删除和插入的时间复杂度（性能比较）？（很重要）

- （1）vector，vector容器在内存中连续分布，支持随机访问(通过下标），时间复杂度是O(1)；如果是无序vector查找的时间复杂度是O(n)，如果是有序vector，采用二分查找则是O(log n)；对于插入操作，在尾部插入最快，中部次之，头部最慢，删除同理。vector占用的内存较大，由于二倍扩容机制可能会导致内存的浪费，内存不足时扩容的拷贝也会造成较大性能开销；

- - vector中push_back()的原理：当容器的大小达到容量后，为了保证内存的连续性，就会再开一个新的内存块，把之前的数据复制过去。每次复制的时间复杂度是O(n)，每次push_back的时间复杂度不太像O(1)，但由于只有很少的情况下才会复制，所以均摊的时间大约是O(1)。

- （2）list由于底层是链表，不支持随机访问，只能通过扫描的方式查找，复杂度为O(n)，但是插入和删除的速度快，只需要调整指针的指向。list不会造成内存的浪费，占用内存较小；但是，请注意前言里说的，List实际上用的时候需要频繁的分配和释放内存，被锐评为狗都不用
- （3）deque采用多块内存串起来的方式提供其元素的存错，每一个内存块存储多个元素，每一块内存存储的元素个数相同，这是他不同于vector采用一块内存来存错所有的元素的方式。deque支持随机访问，但性能比vector要低（需要先查找到对应的内存块，再查找到元素）；对其进行排序，以及排序后的查找会比较慢，想象知名的排序算法，都是针对一段连续内存进行下标访问，而deque是断续的内存块组成。同样排序后的折半查找也无法利用下标直接访问自然性能大打折扣；支持双端扩容，因此在头部和尾部插入和删除元素很快，为O(1)，但是在中间插入和删除元素很慢；
- （4）set和map，底层基于红黑树实现，增删查改的时间复杂度近似O(log n)，红黑树又是基于链表实现，因此占用内存较小；但是同样基于“操作系统以及运行库的内存分配与释放频率和策略才是影响stl各大容器的性能最关键的点”这一法则，他们在理论之外，实际的应用中，总是表现得不是太好。
- （5）unordered_set和unordered_map，底层是基于哈希表实现的，是无序的。理论上增删查改的时间复杂度是O(1)（最差时间复杂度O(n))，实际上数据的分布是否均匀会极大影响容器的性能。

### 3. STL容器的push_back和emplace_back的区别？

- 总结就是：emplace_back(构造参数列表)只调用一次构造函数，而push_back(构造参数列表)会调用一次构造函数+一次移动构造函数。其余情况下，二者相同。

### 4. STL的排序用到了哪种算法，具体如何执行？

- 快速排序、插入排序和堆排序；当数据量很大的时候用快排，划分区段比较小的时候用插入排序，当划分有导致最坏情况的倾向的时候使用堆排序。
- vector、deque，适用sort算法

![img](https://pic1.zhimg.com/80/v2-8fa032e195365f77fb6b980a4ed71958_720w.webp)![image.png](https://cdn.nlark.com/yuque/0/2023/png/29680306/1688711514226-4dfc6cdb-8763-4fc0-a141-b02a82d32e77.png)

### 5. 十大排序算法

![img](https://pic2.zhimg.com/80/v2-42464413907281977a08b433aeb01e95_720w.webp)

```c++
// 冒泡排序
// O（n^2）  O（n^2）  O(n)  稳定
void BubbleSort(std::vector<int> vec) {
	for (int i = 0; i < vec.size() - 1; ++i) {
		bool swapFlag = false;
		for (int j = vec.size() - 1; j > i; --j) {
			if (vec[j] < vec[j - 1]) {
				std::swap(vec[j], vec[j - 1]);
				swapFlag = true;
			}
		}
		if (!swapFlag) {
			break;
		}
	}

	for (int i = 0; i < vec.size(); ++i)
	{
		std::cout << vec[i] << " ";
	}
	std::cout << std::endl;
}

// 选择排序
// O（n^2）  O（n^2）  O（n^2） 不稳定
void SelectSort(std::vector<int> vec) {
	for (int i = 0; i < vec.size() - 1; ++i) {
		int minIndex = i;
		for (int j = i + 1; j < vec.size(); ++j) {
			if (vec[minIndex] > vec[j]) {
				minIndex = j;
			}
		}

		std::swap(vec[minIndex], vec[i]);
	}

	for (int i = 0; i < vec.size(); ++i)
	{
		std::cout << vec[i] << " ";
	}
	std::cout << std::endl;
}


// 插入排序
// O（n^2）  O（n^2）  O(n)  稳定
void InsertSort(std::vector<int> vec) {
	for (int i = 0; i < vec.size(); ++i) {
		for (int j = i; j > 0; --j) {
			if (vec[j] < vec[j - 1]) {
				std::swap(vec[j], vec[j - 1]);
			}
			// 已经排好的不需要再移动
			else {
				break;
			}
		}
	}

	for (int i = 0; i < vec.size(); ++i)
	{
		std::cout << vec[i] << " ";
	}
	std::cout << std::endl;
}


// 希尔排序
// O（n^1.3）  O（n^2）  O(n)  不稳定
void ShellSort(std::vector<int> vec) {
	int gap = vec.size() / 2;

	while (gap >= 1) {
		for (int i = gap; i < vec.size(); ++i) {
			int pre = i - gap;
			int current = vec[i];
			while (pre >= 0 && vec[pre] > current) {
				vec[pre + gap] = vec[pre];
				pre -= gap;
			}
			vec[pre + gap] = current;
		}
		gap /= 2;
	}

	for (int i = 0; i < vec.size(); ++i)
	{
		std::cout << vec[i] << " ";
	}
	std::cout << std::endl;
}


// 归并排序
// O（nlogn）   O（nlogn）   O（nlogn）  稳定
void mergeSort(std::vector<int>& vec, int l, int r) {
	if (l + 1 >= r) {
		return;
	}

	int mid = l + (r - l) / 2;
	mergeSort(vec, l, mid);
	mergeSort(vec, mid, r);

	std::vector<int> temp;

	int ptrLeft = l;
	int ptrRight = mid;
	while (ptrLeft < mid && ptrRight < r) {
		if (vec[ptrLeft] < vec[ptrRight]) {
			temp.push_back(vec[ptrLeft++]);
		}
		else {
			temp.push_back(vec[ptrRight++]);
		}
	}

	while (ptrLeft < mid) {
		temp.push_back(vec[ptrLeft++]);
	}

	while (ptrRight < r) {
		temp.push_back(vec[ptrRight++]);
	}

	for (int i = 0; i < temp.size(); ++i) {
		vec[l + i] = temp[i];
	}

}


// 快速排序
// O（nlogn）   O（n^2）   O（nlogn）   不稳定
void QuickSort(std::vector<int>& vec, int l, int r) {
	if (l + 1 >= r) {
		return;
	}

	int first = l, last = r - 1, key = vec[first];
	while (first < last)
	{
		while (first < last && vec[last] >= key) {
			--last;
		}
		vec[first] = vec[last];

		while (first < last && vec[first] <= key) {
			++first;
		}
		vec[last] = vec[first];
	}

	vec[first] = key;
	QuickSort(vec, l, first);
	QuickSort(vec, first + 1, r);
}

// 堆排序
// O（nlogn）   O（nlogn）   O（nlogn）  不稳定
void HeapSort(std::vector<int>& vec) {
	int last = vec.size() - 1, parent = (last - 1) / 2;
	// 构建最大堆
	for (int i = parent; i >= 0; --i) {
		heap_copare(vec, i, vec.size());
	}

	// 交换并修复堆
	for (int i = last; i >= 0; --i) {
		std::swap(vec[0], vec[i]);		// 将最大的放在最后面，剩余的继续构建最大堆
		heap_copare(vec, 0, i);
	}

}


// 计数排序
// O（n+k）   O（n+k）   O（n+k）  稳定
void CountingSort(std::vector<int> vec) {
	std::vector<int> temp;
	int maxValue = INT_MIN;
	int minValue = INT_MAX;
	for (int i = 0; i < vec.size(); ++i) {
		maxValue = std::max(maxValue, vec[i]);
		minValue = std::min(minValue, vec[i]);
	}

	temp.resize(maxValue - minValue + 1);

	for (int i = 0; i < vec.size(); ++i) {
		++temp[vec[i] - minValue];
	}

	int k = 0;
	for (int i = 0; i < temp.size(); ++i) {
		for (int j = 0; j < temp[i]; ++j) {
			vec[k++] = i + minValue;
		}
	}

	for (int i = 0; i < vec.size(); ++i)
	{
		std::cout << vec[i] << " ";
	}
	std::cout << std::endl;
}


// 基数排序（只能处理正数）
// O（n*k）   O（n*k）   O（n*k）
void RadixSort(std::vector<int> vec) {
	std::vector<std::vector<int>> bucket(10);

	int count = 0; // 参与排序的数目
	bool flag = true;
	for (int times = 1; flag; times *= 10) {
		bucket.clear();
		bucket.resize(10);
		count = 0;

		flag = false;
		for (int i = 0; i < vec.size(); ++i) {
			int p = (vec[i] % (10 * times)) / times;
			bucket[p].push_back(vec[i]);
			if (p) count++;
		}

		if (count != 0) {
			flag = true;
			int k = 0;
			for (int i = 0; i < bucket.size(); ++i) {
				for (int j = 0; j < bucket[i].size(); ++j) {
					vec[k++] = bucket[i][j];
				}
			}
		}
	}

	for (int i = 0; i < vec.size(); ++i)
	{
		std::cout << vec[i] << " ";
	}
	std::cout << std::endl;
}
```

### 6. 红黑树 、AVL树、B树、B+树的性质

- 首先讲平衡二叉树，首先它严格满足左右子树的高度差不超过1，一旦发生就要通过不断的旋转来使他平衡，但是它的查找效率非常高

- - 所以我们经常用它来做查找，而不做插入或删除元素的操作
  - 常用于Windows进程地址空间管理

- 红黑树是一棵二叉查找树实现而来的，是对avl的平衡条件的一种弱化，但同时插入和删除的效率大大增加
- **性质**

- - 每个节点非红即黑.
  - 根节点是黑的。
  - 每个叶节点(叶节点即树尾端NUL指针或NULL节点)都是黑的.
  - 如果一个节点是红的,那么它的两儿子都是黑的.
  - 对于任意节点而言,其到叶子点树NIL指针的每条路径都包含相同数目的黑节点.

![img](https://cdn.nlark.com/yuque/0/2023/png/29680306/1692851445322-34707ce2-c0e4-4a84-9790-9e8aa41fffed.png?x-oss-process=image%2Fresize%2Cw_577%2Climit_0)

**红黑树与平衡二叉树**

首先红黑树是不符合AVL树的平衡条件的，即每个节点的左子树和右子树的高度最多差1的二叉查找树。但是提出了为节点增加颜色，红黑是用非严格的平衡来换取增删节点时候旋转次数的降低，任何不平衡都会在三次旋转之内解决，而AVL是严格平衡树，因此在增加或者删除节点的时候，根据不同情况，旋转的次数比红黑树要多。所以红黑树的插入效率更高！！！

**B树和B+树的区别**

- 这都是由于B+树和B具有这不同的存储结构所造成的区别，以一个m阶树为例。
- **关键字的数量不同**；B+树中分支结点有m个关键字，其叶子结点也有m个，其关键字只是起到了一个索引的作用，但是B树虽然也有m个子结点，但是其只拥有m-1个关键字。
- **存储的位置不同**；B+树中的数据都存储在叶子结点上，也就是其所有叶子结点的数据组合起来就是完整的数据，但是B树的数据存储在每一个结点中，并不仅仅存储在叶子结点上。
- **分支结点的构造不同**；B+树的分支结点仅仅存储着关键字信息和儿子的指针（这里的指针指的是磁盘块的偏移量），也就是说内部结点仅仅包含着索引信息。
- **查询不同**；B树在找到具体的数值以后，则结束，而B+树则需要通过索引找到叶子结点中的数据才结束，也就是说B+树的搜索过程中走了一条从根结点到叶子结点的路径

### 7. STL怎么做内存管理的，Allocator次级分配器的原理，内存池的优势和劣势？

- （1）为了提升内存管理的效率，减少申请小内存造成的内存碎片问题，SGI STL采用了两级配置器，当分配的空间大小超过128B时，会使用第一级空间配置器，直接使用malloc()、realloc()、free()函数进行内存空间的分配和释放。当分配的空间大小小于128B时，将使用第二级空间配置器，采用了内存池技术，通过空闲链表来管理内存。
- （2）次级配置器的内存池管理技术：每次配置一大块内存，并维护对应的自由链表(free list)。若下次再有相同大小的内存配置，就直接从自由链表中拔出。如果客户端释还小额区块，就由配置器回收到自由链表中；配置器共要维护16个自由链表，存放在一个数组里，分别管理大小为8-128B不等的内存块。分配空间的时候，首先根据所需空间的大小（调整为8B的倍数）找到对应的自由链表中相应大小的链表，并从链表中拔出第一个可用的区块；回收的时候也是一样的步骤，先找到对应的自由链表，并插到第一个区块的位置。
- （3）优势：避免内存碎片(这里应该指的是外部碎片)，不需要频繁从用户态切换到内核态，性能高效；劣势：仍然会造成一定的内存浪费，比如申请120B就必须分配128B（内部碎片）。

**二级配置器的内存分配**

- 客户端请求分配大小为n bytes的内存（n <= 128，n已经圆整为8的倍数）
- 检查n对应的free_list是否为空，不为空，直接分配一个内存块给客户，如果为空，到第2步；
- 向内存池申请20个n bytes的内存，如果申请成功，一个返回给客户，另外19个挂到对应free_list节点下；如果有不到20个n bytes的空间，返回一个给客户，另外的全部交给对应free_list节点；如果连一个n bytes的空间都没法分配，进入第3步；
- 向堆申请40个n bytes的空间，如果申请成功，20个n bytes交给内存池，1个返回给客户，19个留给free_list下的节点；如果堆内存不够，进入第四步；
- 从比当前n还大的free_list节点中查找是否有内存可用，如果有，分n bytes给客户，另外部分交给内存池；如果n之后的所有free_list上都没有内存可用，进入第5步；
- 调用第一级配置器的out_of_memory处理机制，尝试释放其它内存。如果可以，返回给客户。

### 8. 什么是哈希表？哈希表的长度为什么要是质数？如何处理冲突？哈希表怎么删除一个元素

- **哈希冲突的含义**

- - 散列可能会存在冲突，比如某个元素通过散列函数计算，确定应该存在下标5的位置，下一次再来一个元素，计算后发现还是存在下标为5的位置，此时就出现了冲突。

- 哈希表是一种根据关键码值直接访问数据的数据结构，它通过把关键码值映射到表中的一个位置来访问元素，以加快查找的速度。这个映射函数叫做哈希函数；
- 哈希表的长度使用质数，可以降低发生冲突的概率，使哈希后的数据更加均匀，如果使用合数，可能会导致很多数据集中分布到一个点上，造成冲突；
- 解决冲突的办法有开放定址法和拉链法，开放定址法包括线性测探、平方测探法，本质上都是对应位置被占用了就向后查找；
- 线性测探法并不会真正的删除一个元素，而是做一个标记，否则可能会导致正常的查找出错
- https://www.cnblogs.com/-beyond/p/7726347.html

### 9. RTTI

- 用于获取运行时对象的类型信息

### 10. 面向对象和泛型编程的区别

### 11. C++多态是怎么实现的

### 12. 为什么析构函数一般写成虚函数

### 13. Lambda表达式（mutable）

### 14. 左值右值

左值、右值（纯右值、将亡值）

万能引用，函数模板，利用引用坍缩规则实现

完美转发：在函数模板中，完全依照模板的参数的类型（即保持参数的左值、右值特征），将参数传递给函数模板中调用的另外一个函数

### 15. RAII

### 16. 智能指针

#### 16.1 std::make_shared的优势和劣势

- 性能提高

  ![img](https://pic1.zhimg.com/80/v2-5f945a545a2d666423e3e8bc275e8ed0_720w.webp)

  - 每个std::shared_ptr都指向一个控制块，控制块包含被指向对象的引用计数以及其他东西。这个控制块的内存是在std::shared_ptr的构造函数中分配的。因此直接使用new，需要一块内存分配给Widget，还要一块内存分配给控制块。

  - 这是因为std::make_shared申请一个单独的内存块来同时存放Widget对象和控制块。这个优化减少了程序的静态大小，因为代码只包含一次内存分配的调用，并且这会加快代码的执行速度，因为内存只分配了一次。另外，使用std::make_shared消除了一些控制块需要记录的信息，这样潜在地减少了程序的总内存占用。

  ![img](https://pic2.zhimg.com/80/v2-68b90de9bd86f29b1bfbdb6d3f4b2a15_720w.webp)

- 异常安全

  ![image-20231212152145953](C:\Users\QZDZ\AppData\Roaming\Typora\typora-user-images\image-20231212152145953.png)

- 缺点：
  - 创建的对象如果没有公有的构造函数时，make_shared无法使用
  - 使用make_shared内存可能无法及时回收，对内存要求要的场景需要注意

### 17. 类的对象存储空间？类对象的大小受哪些因素影响

### 18. this指针

成员函数是如何区别调用它的是哪个类对象的？
答：**借助了this指针，类的每个成员函数都有一个隐藏的参数this指针，它指向类对象。**

**类的构造函数中也同样有this指针，指向的就是正在构造的这个对象。**

在类中（成员、构造、析构函数）对成员变量、成员函数的访问都是借助了this指针

this指针是隐藏的，但也可以显示使用：
1、参数与成员一样时，使用this可以区别出成员与参数名。
2、在成员函数中如果想返回当前对象的指针、引用等，可以使用this指针实现。
3、将this指针作为函数的参数，从一个对象传递给另一个其它类对象，可以实现对象间的交互。

### 19. 检查定位内存泄漏

使用一个接口_CrtDumpMemoryLeaks()，_CrtSetBreakAlloc(453)

### 20. 堆栈的区别

### 21. 指针和引用的区别

### 22. 类如何实现只能静态分配和只能动态分配

### 23. C++中的指针参数传递和引用参数传递有什么区别？底层原理你知道吗

### 24. new / delete 与 malloc / free的异同

### 25. C++和C语言的差别

### 26. define宏定义和const的区别

### 27. strlen和sizeof的区别

### 28. C++的顶层const和底层const

### 29. C++和C的struct区别

### 30. public继承和private继承

### 31. public，protected和private访问和继承权限/public/protected/private的区别？







